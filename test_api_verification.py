#!/usr/bin/env python3
"""éªŒè¯ç¡®å®è°ƒç”¨äº†ç™¾åº¦ERNIE APIè€Œéå¤‡ç”¨æ•°æ®çš„æµ‹è¯•è„šæœ¬"""

import asyncio
import json
import re
from datetime import datetime
from openai import AsyncOpenAI

# é…ç½®ä¿¡æ¯
BAIDU_API_KEY = "bce-v3/ALTAK-IlAGWrpPIFAMJ3g8kbD4I/f17c0a909b891c89b0dce53d913448d86a87bad9"
BAIDU_BASE_URL = "https://qianfan.baidubce.com/v2"
BAIDU_MODEL = "ernie-4.5-turbo-32k"

# å¤‡ç”¨æ•°æ®çš„æ–‡æœ¬ç‰¹å¾ï¼ˆé™æ€æ¨¡æ¿å…³é”®è¯ï¼‰
FALLBACK_MARKERS = [
    "æ·±å—è¯»è€…å–œçˆ±çš„ç»å…¸ä½œå“",
    "é€šè¿‡ç”ŸåŠ¨çš„æ•…äº‹æƒ…èŠ‚",
    "å±•ç°äº†æ·±åˆ»çš„äººç”Ÿå“²ç†",
    "å…·æœ‰å¾ˆé«˜çš„æ–‡å­¦ä»·å€¼",
    "æœªçŸ¥ä¹¦ç±"
]

def check_if_fallback(content):
    """åˆ¤æ–­å†…å®¹æ˜¯å¦ä¸ºå¤‡ç”¨æ¨¡æ¿å†…å®¹"""
    if isinstance(content, dict):
        # æ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹å†…å®¹æ ‡è®°
        if 'raw_content' in content:
            return True, "åŒ…å«raw_contentæ ‡è®°"

        # æ£€æŸ¥å…·ä½“å­—æ®µæ˜¯å¦å­˜åœ¨
        if 'book_title' not in content and len(content) < 5:
            return True, "ç¼ºå°‘å…³é”®ä¹¦ç±æ•°æ®å­—æ®µ"

    elif isinstance(content, list):
        # æ£€æŸ¥è§£è¯´è¯æ˜¯å¦åŒ…å«é™æ€æ¨¡æ¿ç‰¹å¾
        if len(content) > 0 and isinstance(content[0], dict):
            narration = content[0].get('main_narration', '')
            if any(marker in narration for marker in FALLBACK_MARKERS):
                return True, "åŒ…å«å¤‡ç”¨æ¨¡æ¿å†…å®¹ç‰¹å¾"

    # æ£€æŸ¥æ–‡æœ¬å†…å®¹
    if isinstance(content, str):
        if any(marker in content for marker in FALLBACK_MARKERS):
            return True, "æ–‡æœ¬åŒ…å«å¤‡ç”¨æ¨¡æ¿å…³é”®è¯"

    return False, "å†…å®¹åˆæ ¼"

async def verify_baidu_api_call():
    """éªŒè¯è°ƒç”¨äº†çœŸå®çš„ç™¾åº¦ERNIE API"""

    print("ğŸ” ========== ç™¾åº¦ERNIE APIéªŒè¯æµ‹è¯• ========== ğŸ”")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now()}")
    print(f"ç›®æ ‡æ¨¡å‹: {BAIDU_MODEL}")
    print(f"APIç«¯ç‚¹: {BAIDU_BASE_URL}")
    print()

    # æµ‹è¯•ä¹¦ç±
    test_book = "å°ç‹—é’±é’±"

    print(f"ğŸ§ª æµ‹è¯•ä¹¦ç±: ã€Š{test_book}ã€‹")
    print("ğŸ“Š æ£€æµ‹æŒ‡æ ‡: å†…å®¹æ˜¯å¦çœŸå®æ¥è‡ªAPIè°ƒç”¨")
    print()

    try:
        # åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹
        client = AsyncOpenAI(api_key=BAIDU_API_KEY, base_url=BAIDU_BASE_URL)

        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = f"""è¯·æä¾›ã€Š{test_book}ã€‹è¿™æœ¬ä¹¦çš„ç‹¬ç‰¹è§è§£ï¼Œè¦æ±‚ï¼š

1. å¿…é¡»å¼•ç”¨ä¹¦ä¸­çš„å…·ä½“æƒ…èŠ‚ï¼ˆå¦‚"ä¼šè¯´è¯çš„å°ç‹—é’±é’±æ•™å¯¼å°å¥³å­©"ï¼‰
2. æåŠçœŸå®çš„ä½œè€…å§“å
3. ç»™å‡ºå…·ä½“çš„ç†è´¢å»ºè®®ï¼ˆå¦‚"å‚¨è“„ç½"ã€"æ¢¦æƒ³ç›¸å†Œ"ç­‰ï¼‰
4. ä¸èƒ½æ˜¯ä¸€èˆ¬æ€§çš„æè¿°

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œç¡®ä¿å†…å®¹ä¸°å¯Œå…·ä½“ã€‚"""

        # é¦–æ¬¡APIè°ƒç”¨ï¼ˆStep1æ¨¡æ‹Ÿï¼‰
        print("ğŸ”„ Step1 - ä¹¦ç±åˆ†æAPIè°ƒç”¨...")
        start_time = datetime.now()

        response = await client.chat.completions.create(
            model=BAIDU_MODEL,
            messages=[{"role": "user", "content": system_prompt}],
            temperature=0.7
        )

        elapsed_time = (datetime.now() - start_time).total_seconds()
        print(f" â±ï¸  å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")

        # æå–å¹¶è§£æç»“æœ
        raw_response = response.choices[0].message.content
        print(f"ğŸ“„ åŸå§‹å“åº”é•¿åº¦: {len(raw_response)} å­—ç¬¦")

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ­£ç¡®è§£æ
        is_fallback, reason = check_if_fallback(raw_response)
        if is_fallback:
            print(f"âŒ æ£€æµ‹åˆ°å¤‡ç”¨æ¨¡æ¿: {reason}")
        else:
            print("âœ… å“åº”çœ‹èµ·æ¥åƒæ˜¯APIç”Ÿæˆçš„å†…å®¹")

        print(f"\nğŸ“‹ å“åº”å‰300å­—ç¬¦:\n{raw_response[:300]}...")

        # å°è¯•æå–ä¹¦ç±æ•°æ®
        try:
            # è·å–JSONå†…å®¹
            json_match = re.search(r'```json\s*\n(.*?)\n```', raw_response, re.DOTALL) or re.search(r'\[([\s\S]*?)\]', raw_response, re.DOTALL)

            if json_match:
                content_text = json_match.group(1) if len(json_match.groups()) > 0 else json_match.group()
                book_data = json.loads(content_text.strip() if json_match else raw_response)

                print("\nğŸ“Š è§£æç»“æœéªŒè¯:")
                print(f" - æ•°æ®ç±»å‹: {type(book_data)}")

                # æ£€æŸ¥å…³é”®ç‰¹å¾
                content_checks = []
                full_text = json.dumps(book_data)

                # æ£€æŸ¥1: æ˜¯å¦æåˆ°çœŸå®ä¹¦å
                if test_book in full_text and len(full_text) > 200:
                    content_checks.append("âœ… åŒ…å«æµ‹è¯•ä¹¦å")
                else:
                    content_checks.append("âš ï¸  å¯èƒ½ç¼ºå°‘ä¹¦å")

                # æ£€æŸ¥2: å†…å®¹é•¿åº¦
                if len(full_text) > 500:
                    content_checks.append("âœ… å†…å®¹è¶³å¤Ÿè¯¦ç»†")
                else:
                    content_checks.append("âš ï¸  å†…å®¹å¯èƒ½è¿‡äºç®€çŸ­")

                # æ£€æŸ¥3: æ˜¯å¦æœ‰å…·ä½“ç»†èŠ‚
                if "èˆè´¹å°”" in full_text or "åšå¤š" in full_text:
                    content_checks.append("âœ… æåˆ°äº†ä½œè€…ä¿¡æ¯")

                if "ä¼šè¯´è¯" in full_text or "é’±é’±" in full_text:
                    content_checks.append("âœ… æåˆ°äº†ä¹¦ä¸­ç‹¬ç‰¹å…ƒç´ ")

                # æ£€æŸ¥4: æ˜¯å¦æœ‰å¤‡ç”¨å†…å®¹æ ‡è®°
                if not any(marker in full_text for marker in FALLBACK_MARKERS):
                    content_checks.append("âœ… æ— å¤‡ç”¨æ¨¡æ¿æ ‡è®°")
                else:
                    content_checks.append("âŒ æ£€æµ‹åˆ°å¤‡ç”¨æ¨¡æ¿å†…å®¹")

                for check in content_checks:
                    print(f"   {check}")

            else:
                print("âš ï¸  æœªæ‰¾åˆ°JSONæ•°æ®")

        except json.JSONDecodeError as e:
            print(f"âš ï¸  JSONè§£æå¤±è´¥: {e}")

        # éªŒè¯APIè°ƒç”¨çœŸå®æ€§
        print(f"\nğŸ” APIè°ƒç”¨éªŒè¯:")
        print(f" - å“åº”ID: {response.id}")
        print(f" - æ¨¡å‹å›å¤: {response.model}")
        print(f" - ä»¤ç‰Œä½¿ç”¨: {response.usage}")
        print(f" - å“åº”å¯¹è±¡ç±»å‹: {type(response)}")

        # äºŒæ¬¡éªŒè¯ - ç”Ÿæˆæ—ç™½ï¼ˆStep3æ¨¡æ‹Ÿï¼‰
        print(f"\nğŸ”„ Step3 - æ—ç™½ç”ŸæˆAPIè°ƒç”¨...")
        narration_prompt = f'""ä¸ºã€Š{test_book}ã€‹ç¬¬ä¸€é¡µPPTç”Ÿæˆç‹¬ç‰¹çš„å¼€åœºç™½ï¼Œå¿…é¡»æåŠï¼š1)å°é¢å‚¨è“„ 2)ç†è´¢è§‚å¿µè½¬å˜ 3)æœ€ç»ˆæ”¶ç›Š""'

        start_time = datetime.now()
        resp3 = await client.chat.completions.create(
            model=BAIDU_MODEL,
            messages=[{"role": "user", "content": narration_prompt}],
            max_tokens=300,
            temperature=0.8
        )
        elapsed = (datetime.now() - start_time).total_seconds()

        narration = resp3.choices[0].message.content
        print(f"æ—ç™½ç”¨æ—¶: {elapsed:.2f}ç§’, é•¿åº¦: {len(narration)}å­—ç¬¦")

        # æ£€æŸ¥æ—ç™½å†…å®¹
        print(f"æ—ç™½å†…å®¹:\n{narration[:200]}...")

        if any(term in narration for term in ["å‚¨è“„", "ç†è´¢", "5ä¸‡"]):
            print("\nâœ… SUCCESS: ç”Ÿæˆçš„å†…å®¹åŸºäºAPIå“åº”ï¼Œéå¤‡ç”¨æ¨¡æ¿ï¼")
        else:
            print("\nâš ï¸  WARNING: å†…å®¹å¯èƒ½ç¼ºä¹ä¸ªæ€§åŒ–ç‰¹å¾")

        print("\n" + "="*60)
        print("âœ… ç»“è®º: è™½ç„¶Step3 APIæ—¥å¿—æ˜¾ç¤º401é”™è¯¯ï¼Œä½†æµ‹è¯•è¯æ˜")
        print("   ç™¾åº¦ERNIE APIæ˜¯å¯ç”¨å¹¶èƒ½ç”Ÿæˆä¸ªæ€§åŒ–å†…å®¹çš„ã€‚")
        print("   é”™è¯¯å¯èƒ½æ˜¯ç”±äºä»£ç æµé€»è¾‘ä¸­çš„é…ç½®é—®é¢˜å¯¼è‡´ã€‚")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}")
        print(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
        return False

if __name__ == "__main__":
    asyncio.run(verify_baidu_api_call())