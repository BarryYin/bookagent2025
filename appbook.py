import asyncio
import json
import httpx
import re
import os
import sys
import subprocess
from datetime import datetime
from typing import AsyncGenerator, List, Optional
from pathlib import Path

import pytz
from fastapi import FastAPI, Request, HTTPException, Depends, status
from fastapi.responses import StreamingResponse, RedirectResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from openai import AsyncOpenAI, OpenAIError
from pydantic import BaseModel
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
# from google import genai

# å¯¼å…¥è®¤è¯ç›¸å…³æ¨¡å—
from models import UserManager, UserCreate, UserLogin, UserResponse, user_manager, verify_token

# å¯¼å…¥æ–¹æ³•è®ºé…ç½®
sys.path.append(str(Path(__file__).parent / "create"))
try:
    from methodology_config import MethodologyConfig, VoiceConfig, VideoConfig
except ImportError:
    print("Warning: æ–¹æ³•è®ºé…ç½®æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")

# -----------------------------------------------------------------------
# 0. é…ç½®
# -----------------------------------------------------------------------
shanghai_tz = pytz.timezone("Asia/Shanghai")

credentials = json.load(open("credentials.json"))
API_KEY = credentials["API_KEY"]
BASE_URL = credentials.get("BASE_URL", "")

# é…ç½®Qwenæ¨¡å‹å®¢æˆ·ç«¯
QWEN_BASE_URL = "https://api-inference.modelscope.cn/v1/"
QWEN_API_KEY = "ms-9ff035d4-50cb-4adf-afe0-89788293e19e"  # ModelScope Token
QWEN_MODEL = "Qwen/Qwen3-Coder-480B-A35B-Instruct"

if API_KEY.startswith("sk-"):
    client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
    USE_GEMINI = False
    USE_QWEN = False
else:
    # ä½¿ç”¨Qwenæ¨¡å‹
    client = AsyncOpenAI(api_key=QWEN_API_KEY, base_url=QWEN_BASE_URL)
    USE_GEMINI = False
    USE_QWEN = True

if API_KEY.startswith("sk-REPLACE_ME"):
    raise RuntimeError("è¯·åœ¨ç¯å¢ƒå˜é‡é‡Œé…ç½® API_KEY")

templates = Jinja2Templates(directory="templates")

# -----------------------------------------------------------------------
# 1. FastAPI åˆå§‹åŒ–
# -----------------------------------------------------------------------
app = FastAPI(title="AI Animation Backend", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["GET", "POST"],
    allow_headers=["Content-Type", "Authorization"],
)
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/podcast_audio", StaticFiles(directory="podcast_audio"), name="podcast_audio")
app.mount("/covers", StaticFiles(directory="covers"), name="covers")
app.mount("/outputs", StaticFiles(directory="outputs"), name="outputs")

class ChatRequest(BaseModel):
    topic: str
    history: Optional[List[dict]] = None
    step: Optional[int] = None  # å¯é€‰ï¼šæŒ‡å®šæ‰§è¡Œç‰¹å®šæ­¥éª¤

class BookData(BaseModel):
    title: Optional[str] = None
    author: Optional[str] = None
    summary: Optional[str] = None
    key_points: Optional[List[str]] = None
    target_audience: Optional[str] = None
    value: Optional[str] = None
    chapters: Optional[List[str]] = None

class EnhancedGenerateRequest(BaseModel):
    """å¢å¼ºç‰ˆç”Ÿæˆè¯·æ±‚æ¨¡å‹"""
    title: str
    author: Optional[str] = None
    category: Optional[str] = None
    language: Optional[str] = "ä¸­æ–‡"
    description: Optional[str] = None
    user_intent: Optional[str] = None
    methodology: str = "dongyu_literature"
    voice_style: Optional[str] = "professional_style"
    video_style: Optional[str] = "classic_ppt"
    agent_type: str = "exploration"

class InterviewRequest(BaseModel):
    """è¯»åæ„Ÿè®¿è°ˆè¯·æ±‚æ¨¡å‹"""
    message: str
    book_title: str
    book_author: Optional[str] = None
    history: Optional[List[dict]] = None

class VideoExportRequest(BaseModel):
    """è§†é¢‘å¯¼å‡ºè¯·æ±‚æ¨¡å‹"""
    session_id: str
    html_file: str
    audio_prefix: str

# -----------------------------------------------------------------------
# 1.5. ä¹¦ç±å°é¢æœç´¢åŠŸèƒ½ - å¯¼å…¥test_cover.pyçš„å‡½æ•°
# -----------------------------------------------------------------------

# å¯¼å…¥test_cover.pyä¸­çš„å°é¢æœç´¢å‡½æ•°
try:
    from test_cover import search_book_cover as test_cover_search_book_cover
    from test_cover import search_douban_books, search_google_books, get_search_variations
    from test_cover import normalize_text, calculate_similarity, is_better_match
    from test_cover import download_image
    print("âœ… æˆåŠŸå¯¼å…¥test_cover.pyä¸­çš„å°é¢æœç´¢å’Œä¸‹è½½å‡½æ•°")
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥test_cover.pyå¤±è´¥: {e}")
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–çš„å¤‡ç”¨å‡½æ•°
    async def test_cover_search_book_cover(book_title: str, author: str = None) -> str:
        """å¤‡ç”¨å°é¢æœç´¢å‡½æ•°"""
        return get_default_book_cover(book_title)
    
    async def download_image(url: str, save_path: str) -> bool:
        """å¤‡ç”¨ä¸‹è½½å‡½æ•°"""
        return False

# å¯¼å…¥åˆ†ç±»ç®¡ç†å™¨
try:
    from book_category_manager import add_book_to_category, get_all_books_with_categories, get_books_by_category_id, get_categories_summary
    print("âœ… æˆåŠŸå¯¼å…¥åˆ†ç±»ç®¡ç†å™¨")
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥åˆ†ç±»ç®¡ç†å™¨å¤±è´¥: {e}")
    # å¤‡ç”¨å‡½æ•°
    def add_book_to_category(title: str, author: str, category_info: dict, ppt_path: str):
        pass
    
    def get_all_books_with_categories():
        return []
    
    def get_books_by_category_id(category_id: str):
        return []
    
    def get_categories_summary():
        return {}

    def search_books_by_keyword(keyword: str):
        """æœç´¢ä¹¦ç±çš„å…¼å®¹æ€§å‡½æ•°"""
        try:
            # å¦‚æœå¯¼å…¥äº†çœŸæ­£çš„å‡½æ•°ï¼Œä½¿ç”¨å®ƒ
            from book_category_manager import search_books_by_keyword as real_search
            return real_search(keyword)
        except ImportError:
            # å¦åˆ™è¿”å›æ‰€æœ‰ä¹¦ç±å¹¶è¿‡æ»¤
            all_books = get_all_books_with_categories()
            if not keyword:
                return all_books
            
            keyword_lower = keyword.lower()
            filtered_books = []
            for book in all_books:
                # æœç´¢æ ‡é¢˜ã€ä½œè€…æˆ–æè¿°
                if (keyword_lower in book.get('title', '').lower() or 
                    keyword_lower in book.get('author', '').lower() or 
                    keyword_lower in book.get('description', '').lower()):
                    filtered_books.append(book)
            return filtered_books

async def search_book_cover(book_title: str, author: str = None, download: bool = True) -> str:
    """
    æœç´¢ä¹¦ç±å°é¢å›¾ç‰‡
    ä½¿ç”¨test_cover.pyä¸­çš„å‡½æ•°ï¼Œä¼˜å…ˆä½¿ç”¨è±†ç“£å›¾ä¹¦APIï¼Œç„¶åä½¿ç”¨Google Books APIä½œä¸ºå¤‡é€‰
    å¦‚æœdownload=Trueï¼Œä¼šä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°coversç›®å½•
    """
    try:
        # ä½¿ç”¨test_cover.pyä¸­çš„å‡½æ•°
        cover_url = await test_cover_search_book_cover(book_title, author)
        
        # å¦‚æœè¿”å›çš„æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥è¿”å›
        if cover_url.startswith("covers/"):
            return cover_url
        
        # å¦‚æœæ‰¾åˆ°äº†çœŸå®URLä¸”éœ€è¦ä¸‹è½½
        if download and cover_url.startswith("http"):
            # åˆ›å»ºcoversç›®å½•
            import os
            os.makedirs("covers", exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            safe_title = "".join(c for c in book_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_author = "".join(c for c in (author or "") if c.isalnum() or c in (' ', '-', '_')).rstrip()
            filename = f"{safe_title}_{safe_author}.jpg" if safe_author else f"{safe_title}.jpg"
            filename = filename.replace(" ", "_")
            
            save_path = os.path.join("covers", filename)
            
            # ä¸‹è½½å›¾ç‰‡
            print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å°é¢: {filename}")
            success = await download_image(cover_url, save_path)
            
            if success:
                print(f"âœ… å°é¢ä¸‹è½½æˆåŠŸ: {save_path}")
                return save_path
            else:
                print(f"âŒ å°é¢ä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹URL")
                return cover_url
        
        return cover_url
        
    except Exception as e:
        print(f"æœç´¢ä¹¦ç±å°é¢å¤±è´¥: {e}")
        return get_default_book_cover(book_title)

def get_default_book_cover(book_title: str) -> str:
    """
    ç”Ÿæˆé»˜è®¤ä¹¦ç±å°é¢
    åŸºäºä¹¦åç”Ÿæˆä¸€ä¸ªç¾è§‚çš„é»˜è®¤å°é¢æ ·å¼
    """
    # é¢„å®šä¹‰çš„æ¸å˜è‰²æ–¹æ¡ˆ
    gradients = [
        "linear-gradient(135deg, #667eea 0%, #764ba2 100%)",
        "linear-gradient(135deg, #f093fb 0%, #f5576c 100%)",
        "linear-gradient(135deg, #4facfe 0%, #00f2fe 100%)",
        "linear-gradient(135deg, #43e97b 0%, #38f9d7 100%)",
        "linear-gradient(135deg, #fa709a 0%, #fee140 100%)",
        "linear-gradient(135deg, #a8edea 0%, #fed6e3 100%)",
        "linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%)",
        "linear-gradient(135deg, #ff8a80 0%, #ea4c89 100%)",
        "linear-gradient(135deg, #8fd3f4 0%, #84fab0 100%)"
    ]
    
    # æ ¹æ®ä¹¦åå“ˆå¸Œé€‰æ‹©æ¸å˜
    gradient_index = hash(book_title) % len(gradients)
    gradient = gradients[gradient_index]
    
    # è¿”å›CSSæ¸å˜å­—ç¬¦ä¸²ï¼Œå‰ç«¯å¯ä»¥ç›´æ¥ä½¿ç”¨
    return f"gradient:{gradient}"

# -----------------------------------------------------------------------
# 2. æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼šåˆ†ä¸º4ä¸ªæ­¥éª¤
# -----------------------------------------------------------------------

async def step1_extract_book_data(topic: str, methodology: str = "dongyu_literature") -> dict:
    """
    ç¬¬1æ­¥ï¼šæå–ä¹¦æœ¬åŸºæœ¬æ•°æ®ï¼ˆæ”¯æŒæ–¹æ³•è®ºï¼‰
    """
    
    # æ ¹æ®æ–¹æ³•è®ºè°ƒæ•´åˆ†æè§’åº¦
    methodology_context = ""
    if "dongyu" in methodology:
        if "literature" in methodology:
            methodology_context = """
ç‰¹åˆ«å…³æ³¨ï¼š
- ä½œå“çš„æƒ…æ„Ÿæ·±åº¦å’Œäººæ€§å†…æ¶µ
- å¯ä»¥å¼•å‘ä¸ªäººç»å†å…±é¸£çš„è¦ç´ 
- å¤ä»Šä¸­å¤–çš„å¯¹æ¯”å’Œå¼•ç”¨ç´ æ
- å“²å­¦æ€è¾¨å’Œç²¾ç¥ä»·å€¼
- é€‚åˆæƒ…æ„Ÿè¡¨è¾¾çš„ç»†èŠ‚å’Œåœºæ™¯
"""
        elif "autobiography" in methodology:
            methodology_context = """
ç‰¹åˆ«å…³æ³¨ï¼š
- äººç‰©çš„å…³é”®äººç”Ÿé€‰æ‹©å’Œè½¬æŠ˜ç‚¹
- æˆåŠŸä¸å¤±è´¥çš„å¯¹æ¯”åå·®
- æˆé•¿è¿‡ç¨‹ä¸­çš„æ™ºæ…§å’Œæ•™è®­
- å¯å­¦ä¹ çš„äººç”Ÿæ€åº¦å’Œå“æ ¼
- åŠ±å¿—ä»·å€¼å’Œæ¿€åŠ±æ„ä¹‰
"""
        elif "fiction" in methodology:
            methodology_context = """
ç‰¹åˆ«å…³æ³¨ï¼š
- æƒ³è±¡ä¸–ç•Œçš„æ„å»ºå’Œè§„åˆ™
- ç°å®ä¸è™šæ„çš„å¯¹æ¯”å…³ç³»
- æ€ç»´è¾¹ç•Œçš„æ‹“å±•ä»·å€¼
- å¼•å‘æ€è€ƒçš„å“²å­¦é—®é¢˜
- åˆ›æ„å’Œæƒ³è±¡åŠ›çš„ä½“ç°
"""
    elif "luozhenyu" in methodology:
        methodology_context = """
ç‰¹åˆ«å…³æ³¨ï¼š
- è®¤çŸ¥å‡çº§çš„å…·ä½“æ–¹æ³•è®º
- æ—¶ä»£å˜åŒ–å’Œç«äº‰å‹åŠ›
- å®ç”¨çš„æ•ˆç‡æå‡æŠ€å·§
- åº•å±‚é€»è¾‘å’Œç³»ç»Ÿæ€ç»´
- å¯æ‰§è¡Œçš„è¡ŒåŠ¨æŒ‡å—
"""
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å›¾ä¹¦åˆ†æå¸ˆã€‚è¯·å¯¹ã€Š{topic}ã€‹è¿™æœ¬ä¹¦è¿›è¡ŒåŸºæœ¬æ•°æ®æå–å’Œåˆ†æã€‚

{methodology_context}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. ä¹¦åå’Œä½œè€…
2. ä¸»è¦å†…å®¹æ¦‚è¿°ï¼ˆ3-5å¥è¯ï¼‰
3. æ ¸å¿ƒè§‚ç‚¹æˆ–ç†è®ºï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
4. ç›®æ ‡è¯»è€…ç¾¤ä½“
5. ä¹¦ç±çš„ä»·å€¼å’Œæ„ä¹‰
6. é€‚åˆåˆ¶ä½œPPTçš„å…³é”®ç« èŠ‚æˆ–ä¸»é¢˜ï¼ˆ5-8ä¸ªï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œç¡®ä¿åˆ†æè§’åº¦ç¬¦åˆä¸Šè¿°æ–¹æ³•è®ºè¦æ±‚ã€‚
"""

    try:
        if USE_QWEN:
            response = await client.chat.completions.create(
                model=QWEN_MODEL,
                messages=[{"role": "user", "content": system_prompt}],
                temperature=0.7
            )
            result = response.choices[0].message.content
        else:
            response = await client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": system_prompt}],
                temperature=0.7
            )
            result = response.choices[0].message.content

        try:
            book_data = json.loads(result)
        except:
            book_data = {"raw_content": result}
        
        # ç®€å•çš„LLMåˆ†ç±»
        try:
            category_prompt = f"""è¯·å°†ã€Š{topic}ã€‹è¿™æœ¬ä¹¦åˆ†ç±»åˆ°ä»¥ä¸‹5ä¸ªåˆ†ç±»ä¹‹ä¸€ï¼Œåªè¾“å‡ºåˆ†ç±»åç§°ï¼š

æ–‡å­¦ç±»ã€æ•ˆç‡æå‡ç±»ã€è™šæ„ç±»ã€è‡ªä¼ ç±»ã€æ•™æç±»

åªè¾“å‡ºåˆ†ç±»åç§°ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
            
            if USE_QWEN:
                category_response = await client.chat.completions.create(
                    model=QWEN_MODEL,
                    messages=[{"role": "user", "content": category_prompt}],
                    temperature=0.3
                )
                category = category_response.choices[0].message.content.strip()
            else:
                category_response = await client.chat.completions.create(
                    model="gpt-4",
                    messages=[{"role": "user", "content": category_prompt}],
                    temperature=0.3
                )
                category = category_response.choices[0].message.content.strip()
            
            # åˆ†ç±»æ˜ å°„
            category_mapping = {
                'æ–‡å­¦ç±»': {'id': 'literature', 'name': 'æ–‡å­¦ç±»', 'color': '#E74C3C', 'icon': 'ğŸ“–'},
                'æ•ˆç‡æå‡ç±»': {'id': 'efficiency', 'name': 'æ•ˆç‡æå‡ç±»', 'color': '#27AE60', 'icon': 'âš¡'},
                'è™šæ„ç±»': {'id': 'fiction', 'name': 'è™šæ„ç±»', 'color': '#9B59B6', 'icon': 'ğŸ”®'},
                'è‡ªä¼ ç±»': {'id': 'biography', 'name': 'è‡ªä¼ ç±»', 'color': '#F39C12', 'icon': 'ğŸ‘¤'},
                'æ•™æç±»': {'id': 'textbook', 'name': 'æ•™æç±»', 'color': '#34495E', 'icon': 'ğŸ“š'}
            }
            
            category_info = category_mapping.get(category, category_mapping['æ–‡å­¦ç±»'])
            book_data['category_id'] = category_info['id']
            book_data['category_name'] = category_info['name']
            book_data['category_color'] = category_info['color']
            book_data['category_icon'] = category_info['icon']
            book_data['category_confidence'] = 1.0
            
            print(f"ğŸ“š ä¹¦ç±ã€Š{topic}ã€‹åˆ†ç±»ä¸º: {category_info['name']}")
            
        except Exception as e:
            print(f"åˆ†ç±»å¤±è´¥: {e}")
            # é»˜è®¤åˆ†ç±»
            book_data['category_id'] = 'literature'
            book_data['category_name'] = 'æ–‡å­¦ç±»'
            book_data['category_color'] = '#E74C3C'
            book_data['category_icon'] = 'ğŸ“–'
            book_data['category_confidence'] = 0.0
        
        # æœç´¢ä¹¦ç±å°é¢ï¼ˆæš‚æ—¶ç®€åŒ–ï¼Œé¿å…é˜»å¡ï¼‰
        try:
            # ä»è§£æçš„æ•°æ®ä¸­æå–ä¹¦åå’Œä½œè€…
            if isinstance(book_data, dict) and 'raw_content' not in book_data:
                book_title = book_data.get('book_title', topic)
                author = book_data.get('author', '')
            else:
                # ä»raw_contentä¸­æå–ä¿¡æ¯
                book_title = topic
                author = ''
                if 'raw_content' in book_data:
                    content = str(book_data['raw_content'])
                    # å°è¯•ä»å†…å®¹ä¸­æå–ä½œè€…ä¿¡æ¯
                    author_match = re.search(r'"author":\s*"([^"]+)"', content)
                    if author_match:
                        author = author_match.group(1)
            
            # æš‚æ—¶ä½¿ç”¨é»˜è®¤å°é¢ï¼ˆé¿å…ç½‘ç»œè°ƒç”¨é˜»å¡ï¼‰
            print(f"ğŸ“¸ æš‚æ—¶ä½¿ç”¨é»˜è®¤å°é¢: {book_title}")
            book_data['cover_url'] = get_default_book_cover(book_title)
            
        except Exception as cover_error:
            print(f"å°é¢å¤„ç†å¤±è´¥: {cover_error}")
            book_data['cover_url'] = get_default_book_cover(topic)
        
        return book_data
            
    except Exception as e:
        # è¯¦ç»†è®°å½•é”™è¯¯ä¿¡æ¯
        error_str = str(e)
        print(f"Step1 APIè°ƒç”¨å‡ºé”™ï¼Œé”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"é”™è¯¯è¯¦æƒ…: {error_str}")
        
        # æ ¹æ®é”™è¯¯ç±»å‹æä¾›ä¸åŒçš„å¤„ç†
        if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
            print("æ£€æµ‹åˆ°APIé…é¢é™åˆ¶ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
        elif "ConnectError" in error_str or "SSL" in error_str or "EOF" in error_str:
            print("æ£€æµ‹åˆ°ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
        elif "timeout" in error_str.lower():
            print("æ£€æµ‹åˆ°è¯·æ±‚è¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
        else:
            print(f"æœªçŸ¥é”™è¯¯ç±»å‹ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {error_str}")
        
        fallback_data = get_fallback_book_data(topic)
        fallback_data['cover_url'] = get_default_book_cover(topic)
        return fallback_data

async def step2_create_ppt_slides(book_data: dict, methodology: str = "dongyu_literature", video_style: str = "classic_ppt") -> list:
    """
    ç¬¬2æ­¥ï¼šåˆ›å»ºPPTç”»é¢ç»“æ„ï¼ˆæ”¯æŒæ–¹æ³•è®ºå’Œè§†é¢‘é£æ ¼ï¼‰
    """
    
    # æ ¹æ®æ–¹æ³•è®ºè°ƒæ•´PPTç»“æ„
    methodology_structure = ""
    if "dongyu_literature" in methodology:
        methodology_structure = """
## è‘£å®‡è¾‰å¼æ–‡å­¦ä½œå“PPTç»“æ„ï¼š
1. **æƒ…æ„Ÿå¼€åœºé¡µ** - æƒ…æ„Ÿæé—® + é‡‘å¥å¼•å…¥
2. **ä¸ªäººç»å†é¡µ** - è‡ªèº«æ•…äº‹åˆ†äº«ï¼Œå»ºç«‹è¿æ¥
3. **æ•…äº‹é‡æ„é¡µ** - è‹±é›„ä¹‹æ—… + æ—¶ä»£èƒŒæ™¯
4. **ç»†èŠ‚æ”¾å¤§é¡µ** - ç»å…¸åœºæ™¯ + è±¡å¾æ„ä¹‰
5. **å¤ä»Šå¯¹æ¯”é¡µ** - å¤å…¸åå¥ + ç°ä»£æ€è€ƒ
6. **ä½œè€…æ·±æŒ–é¡µ** - åˆ›ä½œåŠ¨æœº + äººç”Ÿä½“éªŒ
7. **ç°å®å…³ç…§é¡µ** - å½“ä¸‹å¯¹æ¯” + ä»·å€¼å¼•å¯¼
8. **æ”¶è·å‡åé¡µ** - ç²¾ç¥è´¢å¯Œ + äººç”ŸæŒ‡å¯¼

è®¾è®¡ç‰¹ç‚¹ï¼š
- æ¸©æš–çš„è‰²è°ƒï¼Œè¥é€ æƒ…æ„Ÿæ°›å›´
- å¤§é‡å¼•ç”¨å’Œå¯¹æ¯”
- æ³¨é‡æƒ…æ„Ÿå…±é¸£
- æ•…äº‹åŒ–è¡¨è¾¾"""
    elif "dongyu_autobiography" in methodology:
        methodology_structure = """
## è‘£å®‡è¾‰å¼è‡ªä¼ ä½“PPTç»“æ„ï¼š
1. **åå·®å¼€åœºé¡µ** - æˆå°± vs å‡ºèº«çš„å¯¹æ¯”
2. **äººç”Ÿè½¨è¿¹é¡µ** - å…³é”®è½¬æŠ˜ç‚¹æ—¶é—´è½´
3. **é€‰æ‹©åˆ†æé¡µ** - é‡å¤§å†³å®šçš„èƒŒæ™¯å’Œä»£ä»·
4. **å›°éš¾å…‹æœé¡µ** - æŒ«æŠ˜ä¸­çš„åšæŒå’Œæˆé•¿
5. **æ™ºæ…§æç‚¼é¡µ** - äººç”Ÿç»éªŒçš„æ·±åº¦æ€è€ƒ
6. **ä»·å€¼ä¼ é€’é¡µ** - å¯¹è¯»è€…çš„å¯å‘æ„ä¹‰

è®¾è®¡ç‰¹ç‚¹ï¼š
- å¯¹æ¯”å¼ºçƒˆçš„è§†è§‰å…ƒç´ 
- æ—¶é—´è½´å¼å¸ƒå±€
- åŠ±å¿—æ„Ÿçš„è‰²å½©æ­é…"""
    elif "luozhenyu_efficiency" in methodology:
        methodology_structure = """
## ç½—æŒ¯å®‡å¼æ•ˆç‡æå‡PPTç»“æ„ï¼š
1. **ç„¦è™‘åˆ¶é€ é¡µ** - å·®è·å¯¹æ¯” + æ—¶ä»£ç´§è¿«æ„Ÿ
2. **è®¤çŸ¥å‡çº§é¡µ** - åº•å±‚é€»è¾‘æ­ç¤º
3. **æ–¹æ³•æ‹†è§£é¡µ** - ç³»ç»ŸåŒ–çš„è§£å†³æ–¹æ¡ˆ
4. **æ•°æ®æ”¯æ’‘é¡µ** - æƒå¨èƒŒä¹¦ + æ•ˆæœè¯æ˜
5. **è¡ŒåŠ¨æŒ‡å—é¡µ** - å…·ä½“å¯æ‰§è¡Œçš„æ­¥éª¤
6. **è®¤çŸ¥å˜ç°é¡µ** - å­¦ä»¥è‡´ç”¨çš„ä»·å€¼ä½“ç°

è®¾è®¡ç‰¹ç‚¹ï¼š
- å¼ºå¯¹æ¯”è‰²å½©ï¼ˆæ©™è‰²ã€é»‘è‰²ï¼‰
- æ•°æ®å¯è§†åŒ–
- é€»è¾‘æ¸…æ™°çš„å¸ƒå±€
- ç´§è¿«æ„Ÿçš„è§†è§‰è¡¨è¾¾"""
    else:
        methodology_structure = """
## é€šç”¨PPTç»“æ„ï¼š
1. **å¼€åœºé¡µ** - ä¹¦åå¤§æ ‡é¢˜ï¼Œç®€æ´èƒŒæ™¯
2. **ä½œè€…ä»‹ç»é¡µ** - ä½œè€…ä¿¡æ¯ï¼Œä¼˜é›…å¸ƒå±€
3. **æ ¸å¿ƒè§‚ç‚¹é¡µ** - å•ä¸€é‡ç‚¹ï¼Œå¤§å­—ä½“å±•ç¤º
4. **æ•°æ®å±•ç¤ºé¡µ** - å…³é”®æ•°å­—ï¼Œè§†è§‰åŒ–å‘ˆç°
5. **å¼•ç”¨é¡µ** - ä¹¦ä¸­é‡‘å¥ï¼Œè‰ºæœ¯åŒ–æ’ç‰ˆ
6. **æ€»ç»“é¡µ** - æ ¸å¿ƒä»·å€¼ï¼Œcall-to-action"""
    
    # æ ¹æ®è§†é¢‘é£æ ¼è°ƒæ•´è§†è§‰å…ƒç´ 
    style_config = ""
    if video_style == "storytelling":
        style_config = """
è§†è§‰é£æ ¼é…ç½®ï¼š
- æ¸©æš–çš„è‰²è°ƒï¼ˆæš–æ©™ã€ç±³ç™½ã€æ·±æ£•ï¼‰
- æ‰‹ç»˜é£æ ¼çš„æ’å›¾å…ƒç´ 
- åœ†æ¶¦çš„è¾¹è§’è®¾è®¡
- æ¸©é¦¨çš„å­—ä½“é€‰æ‹©
- æ¸å˜èƒŒæ™¯
"""
    elif video_style == "modern_presentation":
        style_config = """
è§†è§‰é£æ ¼é…ç½®ï¼š
- ç°ä»£æ„Ÿå¼ºçš„é…è‰²ï¼ˆæ·±è“ã€äº®æ©™ã€çº¯ç™½ï¼‰
- å‡ ä½•å›¾å½¢è£…é¥°
- æ— è¡¬çº¿å­—ä½“
- åŠ¨æ„Ÿçš„å¸ƒå±€
- æ¸å˜å’Œé˜´å½±æ•ˆæœ
"""
    else:  # classic_ppt
        style_config = """
è§†è§‰é£æ ¼é…ç½®ï¼š
- å•†åŠ¡æ„Ÿé…è‰²ï¼ˆæ·±è“ã€ç°ç™½ã€é‡‘è‰²ï¼‰
- ç®€æ´çš„çº¿æ¡è®¾è®¡
- ç»å…¸çš„å­—ä½“æ­é…
- å¯¹ç§°çš„å¸ƒå±€
- ä¸“ä¸šçš„è¡¨æ ¼å’Œå›¾è¡¨
"""

    system_prompt = f"""åŸºäºä»¥ä¸‹ä¹¦ç±æ•°æ®ï¼Œè®¾è®¡ç¬¦åˆæŒ‡å®šæ–¹æ³•è®ºçš„PPTç”»é¢ç»“æ„ï¼š

{json.dumps(book_data, ensure_ascii=False, indent=2)}

{methodology_structure}

{style_config}

æ¯é¡µPPTè¯·åŒ…å«ä»¥ä¸‹ç»“æ„ï¼š
- slide_number: é¡µé¢ç¼–å·
- slide_type: é¡µé¢ç±»å‹
- title: ä¸»æ ‡é¢˜
- subtitle: å‰¯æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
- main_content: æ ¸å¿ƒå†…å®¹
- visual_elements: è§†è§‰å…ƒç´ é…ç½®
- animation_entrance: å…¥åœºåŠ¨ç”»ç±»å‹
- key_message: æ ¸å¿ƒä¿¡æ¯

é‡è¦è¦æ±‚ï¼š
1. å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ–¹æ³•è®ºçš„ç»“æ„æ¥ç»„ç»‡å†…å®¹
2. å†…å®¹è¡¨è¾¾æ–¹å¼è¦ä½“ç°æ–¹æ³•è®ºç‰¹è‰²
3. è§†è§‰é£æ ¼è¦ç¬¦åˆé…ç½®è¦æ±‚
4. ç¡®ä¿æ¯é¡µå†…å®¹æœ‰æ·±åº¦å’Œæ„ŸæŸ“åŠ›

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›ã€‚
"""

    try:
        if USE_QWEN:
            response = await client.chat.completions.create(
                model=QWEN_MODEL,
                messages=[{"role": "user", "content": system_prompt}],
                temperature=0.8
            )
            result = response.choices[0].message.content
        else:
            response = await client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": system_prompt}],
                temperature=0.8
            )
            result = response.choices[0].message.content

        try:
            return json.loads(result)
        except:
            return [{"raw_content": result}]
            
    except Exception as e:
        # APIé…é¢ç”¨å®Œæˆ–å…¶ä»–é”™è¯¯æ—¶ï¼Œè¿”å›é»˜è®¤æ•°æ®
        if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
            book_title = extract_book_title(book_data) if book_data else "æœªçŸ¥ä¹¦ç±"
            print(f"Step2 APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return get_fallback_slides_data(book_title)
        else:
            book_title = extract_book_title(book_data) if book_data else "æœªçŸ¥ä¹¦ç±"
            print(f"Step2 æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return get_fallback_slides_data(book_title)

async def step3_create_narration(slides: list, book_data: dict, methodology: str = "dongyu_literature") -> list:
    """
    ç¬¬3æ­¥ï¼šä¸ºæ¯é¡µPPTåˆ›å»ºè§£è¯´è¯ï¼ˆæ”¯æŒæ–¹æ³•è®ºé£æ ¼ï¼‰
    """
    
    # æ ¹æ®æ–¹æ³•è®ºè°ƒæ•´è§£è¯´é£æ ¼
    narration_style = ""
    if "dongyu_literature" in methodology:
        narration_style = """
## è‘£å®‡è¾‰å¼æ–‡å­¦ä½œå“è§£è¯´é£æ ¼ï¼š
1. **æƒ…æ„Ÿå…±é¸£å¼å¼€åœº**ï¼š
   - "ä½ æœ‰æ²¡æœ‰è¿‡è¿™æ ·çš„ç»å†..."
   - "å½“æˆ‘ç¬¬ä¸€æ¬¡è¯»åˆ°è¿™æ®µæ–‡å­—çš„æ—¶å€™..."
   - "åœ¨é‚£ä¸ªç‰¹æ®Šçš„æ—¶åˆ»..."

2. **è¡¨è¾¾æ–¹å¼**ï¼š
   - æ¸©æš–äº²åˆ‡çš„è¯­è°ƒ
   - ç»“åˆè‡ªèº«ç»å†å’Œæ„Ÿå—
   - å¤§é‡çš„æ¯”å–»å’Œç±»æ¯”
   - å¤å…¸æ–‡å­¦çš„å¼•ç”¨å’Œå¯¹æ¯”
   - å“²æ€ä¸ç”Ÿæ´»çš„ç»“åˆ

3. **ç»“æ„æ¨¡å¼**ï¼š
   - ä¸ªäººä½“éªŒ â†’ æ–‡å­¦å‡å â†’ äººç”Ÿæ„Ÿæ‚Ÿ
   - å¤ä»Šå¯¹æ¯” â†’ æ·±åº¦æ€è€ƒ â†’ ä»·å€¼å¯å‘

4. **è¯­è¨€ç‰¹è‰²**ï¼š
   - "æˆ‘æƒ³èµ·äº†..."ã€"å°±åƒ..."ã€"æ­£å¦‚...æ‰€è¯´"
   - å……æ»¡è¯—æ„çš„è¡¨è¾¾
   - æ¸©æš–çš„äººæ–‡å…³æ€€
   - æ·±åº¦çš„æ–‡åŒ–å†…æ¶µ"""
    elif "dongyu_autobiography" in methodology:
        narration_style = """
## è‘£å®‡è¾‰å¼è‡ªä¼ ä½“è§£è¯´é£æ ¼ï¼š
1. **åå·®å¯¹æ¯”å¼å¼€åœº**ï¼š
   - "è°èƒ½æƒ³åˆ°..."
   - "åœ¨æˆåŠŸçš„èƒŒå..."
   - "ä»...åˆ°...çš„è½¬å˜"

2. **è¡¨è¾¾æ–¹å¼**ï¼š
   - çœŸè¯šå¦ç‡çš„åˆ†äº«
   - æˆé•¿ç»å†çš„æ·±åº¦æŒ–æ˜
   - é€‰æ‹©èƒŒåçš„æ€è€ƒè¿‡ç¨‹
   - å¤±è´¥ä¸æˆåŠŸçš„å¯¹æ¯”

3. **ç»“æ„æ¨¡å¼**ï¼š
   - ç°çŠ¶å±•ç¤º â†’ å›æº¯ç»å† â†’ å¯å‘æ€è€ƒ
   - å›°éš¾æè¿° â†’ å…‹æœè¿‡ç¨‹ â†’ ä»·å€¼ä¼ é€’"""
    elif "luozhenyu_efficiency" in methodology:
        narration_style = """
## ç½—æŒ¯å®‡å¼æ•ˆç‡æå‡è§£è¯´é£æ ¼ï¼š
1. **ç„¦è™‘åˆ¶é€ å¼å¼€åœº**ï¼š
   - "ä½ çŸ¥é“å—ï¼Œç°åœ¨çš„æ—¶ä»£..."
   - "æœ‰ä¸€ä¸ªæ®‹é…·çš„äº‹å®..."
   - "æˆ‘ä»¬é¢ä¸´ç€å‰æ‰€æœªæœ‰çš„æŒ‘æˆ˜..."

2. **è¡¨è¾¾æ–¹å¼**ï¼š
   - ç´§è¿«æ„Ÿçš„è¥é€ 
   - æ•°æ®å’Œæ¡ˆä¾‹çš„å †å 
   - é€»è¾‘æ¸…æ™°çš„è®ºè¯
   - æƒå¨ä¸“å®¶çš„èƒŒä¹¦
   - ç«‹ç«¿è§å½±çš„è§£å†³æ–¹æ¡ˆ

3. **ç»“æ„æ¨¡å¼**ï¼š
   - é—®é¢˜æš´éœ² â†’ åŸå› åˆ†æ â†’ æ–¹æ³•æä¾›
   - å·®è·å¯¹æ¯” â†’ è®¤çŸ¥å‡çº§ â†’ è¡ŒåŠ¨æŒ‡å—

4. **è¯­è¨€ç‰¹è‰²**ï¼š
   - "å…³é”®æ˜¯..."ã€"æ ¸å¿ƒåœ¨äº..."ã€"æœ¬è´¨ä¸Š..."
   - å¼ºçƒˆçš„æ—¶é—´ç´§è¿«æ„Ÿ
   - æ˜ç¡®çš„è¡ŒåŠ¨æŒ‡å¯¼
   - å¯é‡åŒ–çš„æˆæœé¢„æœŸ"""
    else:
        narration_style = """
## é€šç”¨è§£è¯´é£æ ¼ï¼š
1. **å¼€åœºæ–¹å¼**ï¼š
   - ç®€æ´æœ‰åŠ›çš„å¼€åœº
   - ç›´æ¥åˆ‡å…¥ä¸»é¢˜
   - åˆ¶é€ æœŸå¾…æ„Ÿ

2. **è¡¨è¾¾æ–¹å¼**ï¼š
   - ç®€æ´æ˜äº†ï¼Œé¿å…å†—é•¿
   - ä½¿ç”¨æ•°æ®å’Œäº‹å®è¯´è¯
   - æƒ…æ„ŸåŒ–çš„è¯­è¨€
   - é€‚å½“çš„åœé¡¿å’Œå¼ºè°ƒ"""

    system_prompt = f"""åŸºäºä»¥ä¸‹PPTç”»é¢ç»“æ„å’Œä¹¦ç±æ•°æ®ï¼Œä¸ºæ¯é¡µPPTåˆ›å»ºæŒ‡å®šæ–¹æ³•è®ºé£æ ¼çš„è§£è¯´è¯ï¼š

ä¹¦ç±æ•°æ®ï¼š
{json.dumps(book_data, ensure_ascii=False, indent=2)}

PPTç”»é¢ç»“æ„ï¼š
{json.dumps(slides, ensure_ascii=False, indent=2)}

{narration_style}

æ¯é¡µè§£è¯´è¯åŒ…å«ï¼š
- slide_number: é¡µé¢ç¼–å·
- opening: å¼€åœºç™½ï¼ˆ1-2å¥è¯ï¼Œå¸å¼•æ³¨æ„ï¼‰
- main_narration: ä¸»è¦è§£è¯´å†…å®¹ï¼ˆ2-3åˆ†é’Ÿï¼Œæ·±å…¥æµ…å‡ºï¼‰
- key_emphasis: é‡ç‚¹å¼ºè°ƒçš„å†…å®¹ï¼ˆé‡‘å¥æˆ–æ ¸å¿ƒè§‚ç‚¹ï¼‰
- transition: è¿‡æ¸¡è¯­ï¼ˆè¿æ¥ä¸‹ä¸€é¡µï¼‰
- timing: æ—¶é—´æ§åˆ¶ä¿¡æ¯
- tone: è¯­è°ƒé£æ ¼
- voice_emotion: è¯­éŸ³æƒ…æ„Ÿæ ‡è®°ï¼ˆç”¨äºè¯­éŸ³åˆæˆï¼‰

è§£è¯´è¯è¦æ±‚ï¼š
- ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ–¹æ³•è®ºçš„è¡¨è¾¾é£æ ¼
- è¯­è¨€è¦ä½“ç°æ–¹æ³•è®ºçš„ç‹¬ç‰¹ç‰¹è‰²
- ç»“åˆä¹¦ç±å†…å®¹ï¼Œä¿æŒé£æ ¼ä¸€è‡´æ€§
- é€‚åˆç°åœºæ¼”è®²çš„èŠ‚å¥
- åŒ…å«é€‚å½“çš„æƒ…æ„Ÿæ¸²æŸ“å’Œè¯­éŸ³æç¤º

è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›ã€‚
"""

    try:
        if USE_QWEN:
            response = await client.chat.completions.create(
                model=QWEN_MODEL,
                messages=[{"role": "user", "content": system_prompt}],
                temperature=0.8
            )
            result = response.choices[0].message.content
        else:
            response = await client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": system_prompt}],
                temperature=0.8
            )
            result = response.choices[0].message.content

        try:
            return json.loads(result)
        except:
            return [{"raw_content": result}]
            
    except Exception as e:
        # APIé…é¢ç”¨å®Œæˆ–å…¶ä»–é”™è¯¯æ—¶ï¼Œè¿”å›é»˜è®¤æ•°æ®
        if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
            book_title = extract_book_title(book_data) if book_data else "æœªçŸ¥ä¹¦ç±"
            print(f"Step3 APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return get_fallback_narrations_data(book_title)
        else:
            book_title = extract_book_title(book_data) if book_data else "æœªçŸ¥ä¹¦ç±"
            print(f"Step3 æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {e}")
            return get_fallback_narrations_data(book_title)

async def step4_generate_html(slides: list, narrations: list, book_data: dict, methodology: str = "dongyu_literature", enable_voice: bool = False, book_title: str = None) -> str:
    """
    ç¬¬4æ­¥ï¼šå°†ç”»é¢å’Œè§£è¯´è¯è½¬æ¢ä¸ºHTMLæ ¼å¼ï¼ˆæ”¯æŒè¯­éŸ³å’Œæ–¹æ³•è®ºé£æ ¼ï¼‰
    """
    
    # ç›´æ¥ä½¿ç”¨å¯é çš„å†…ç½®æ¨¡æ¿ï¼Œä¸å†è°ƒç”¨AI
    print(f"DEBUG: step4_generate_htmlç›´æ¥è°ƒç”¨generate_reliable_ppt_html_internal")
    print(f"DEBUG: slidesç±»å‹: {type(slides)}, é•¿åº¦: {len(slides) if isinstance(slides, list) else 'N/A'}")
    print(f"DEBUG: narrationsç±»å‹: {type(narrations)}, é•¿åº¦: {len(narrations) if isinstance(narrations, list) else 'N/A'}")
    print(f"DEBUG: ä¼ é€’çš„book_title: {book_title}")
    result = generate_reliable_ppt_html_internal(slides, narrations, book_data, book_title)
    print(f"DEBUG: ç”Ÿæˆçš„HTMLé•¿åº¦: {len(result)}, åŒ…å«data-speech: {'data-speech' in result}")
    return result

async def llm_event_stream(
    topic: str,
    history: Optional[List[dict]] = None,
    model: str = QWEN_MODEL,
    user_id: Optional[int] = None,
) -> AsyncGenerator[str, None]:
    """
    ä¸»æµå¼ç”Ÿæˆå™¨ï¼šä¾æ¬¡æ‰§è¡Œ4ä¸ªæ­¥éª¤ï¼Œæ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†æ—¥å¿—
    """
    history = history or []
    
    # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯IDç”¨äºä¿å­˜æ–‡ä»¶
    import uuid
    session_id = str(uuid.uuid4())
    
    try:
        # å¼€å§‹æ€è€ƒä¸è§„åˆ’é˜¶æ®µ
        yield f"data: {json.dumps({'log': 'ğŸ¤” Kiro Agent å¼€å§‹æ€è€ƒä¸è§„åˆ’...'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.5)
        
        yield f"data: {json.dumps({'log': f'ğŸ“š åˆ†æä¸»é¢˜: {topic}'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        yield f"data: {json.dumps({'log': 'ğŸ¯ åˆ¶å®šç”Ÿæˆç­–ç•¥: 4æ­¥éª¤æµç¨‹'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ­¥éª¤1: æå–ä¹¦ç±åŸºæœ¬æ•°æ®'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ­¥éª¤2: è®¾è®¡PPTç”»é¢ç»“æ„'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ­¥éª¤3: åˆ›å»ºè§£è¯´è¯å†…å®¹'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ æ­¥éª¤4: ç”Ÿæˆå®Œæ•´HTML'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.5)
        
        # æ­¥éª¤1ï¼šæå–ä¹¦æœ¬æ•°æ®
        yield f"data: {json.dumps({'log': 'ğŸ” [æ­¥éª¤1/4] æ­£åœ¨åˆ†æä¹¦ç±æ•°æ®...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ è°ƒç”¨AIæ¨¡å‹åˆ†æä¹¦ç±ä¿¡æ¯'}, ensure_ascii=False)}\n\n"
        
        try:
            book_data = await step1_extract_book_data(topic)
        except Exception as e:
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
                yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸  APIè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®'}, ensure_ascii=False)}\n\n"
                book_data = get_fallback_book_data(topic)
            else:
                yield f"data: {json.dumps({'log': f'  â”œâ”€ âš ï¸  æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {str(e)}'}, ensure_ascii=False)}\n\n"
                book_data = get_fallback_book_data(topic)
        
        # æå–ä¹¦åç”¨äºæ—¥å¿—æ˜¾ç¤º
        book_title = topic
        if isinstance(book_data, dict) and 'raw_content' in book_data:
            try:
                import re
                title_match = re.search(r'"(?:book_title|title)":\s*"([^"]+)"', str(book_data['raw_content']))
                if title_match:
                    book_title = title_match.group(1)
            except:
                pass
        
        yield f"data: {json.dumps({'log': f'  â”œâ”€ è¯†åˆ«ä¹¦ç±: ã€Š{book_title}ã€‹'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… ä¹¦ç±æ•°æ®åˆ†æå®Œæˆ'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # æ­¥éª¤2ï¼šåˆ›å»ºPPTç”»é¢
        yield f"data: {json.dumps({'log': 'ğŸ¨ [æ­¥éª¤2/4] æ­£åœ¨è®¾è®¡PPTç”»é¢ç»“æ„...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ åŸºäºè‹¹æœå‘å¸ƒä¼šé£æ ¼è®¾è®¡'}, ensure_ascii=False)}\n\n"
        
        try:
            slides = await step2_create_ppt_slides(book_data)
        except Exception as e:
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
                yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸  APIè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®'}, ensure_ascii=False)}\n\n"
                slides = get_fallback_slides_data(book_title)
            else:
                yield f"data: {json.dumps({'log': f'  â”œâ”€ âš ï¸  æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {str(e)}'}, ensure_ascii=False)}\n\n"
                slides = get_fallback_slides_data(book_title)
        
        slide_count = len(slides) if isinstance(slides, list) else 3
        yield f"data: {json.dumps({'log': f'  â”œâ”€ è®¾è®¡äº† {slide_count} é¡µPPTç”»é¢'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… PPTç”»é¢è®¾è®¡å®Œæˆ'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # æ­¥éª¤3ï¼šåˆ›å»ºè§£è¯´è¯
        yield f"data: {json.dumps({'log': 'ğŸ¤ [æ­¥éª¤3/4] æ­£åœ¨åˆ›å»ºè§£è¯´è¯å†…å®¹...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ ä¸ºæ¯é¡µPPTåŒ¹é…è§£è¯´è¯'}, ensure_ascii=False)}\n\n"
        
        try:
            narrations = await step3_create_narration(slides, book_data)
        except Exception as e:
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
                yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸  APIè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®'}, ensure_ascii=False)}\n\n"
                narrations = get_fallback_narrations_data(book_title)
            else:
                yield f"data: {json.dumps({'log': f'  â”œâ”€ âš ï¸  æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {str(e)}'}, ensure_ascii=False)}\n\n"
                narrations = get_fallback_narrations_data(book_title)
        
        narration_count = len(narrations) if isinstance(narrations, list) else slide_count
        yield f"data: {json.dumps({'log': f'  â”œâ”€ ç”Ÿæˆäº† {narration_count} æ®µè§£è¯´è¯'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… è§£è¯´è¯åˆ›å»ºå®Œæˆ'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # æ­¥éª¤4ï¼šç”ŸæˆHTML
        yield f"data: {json.dumps({'log': 'ğŸ”§ [æ­¥éª¤4/4] æ­£åœ¨ç”Ÿæˆå®Œæ•´HTML...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ ä½¿ç”¨å¯é çš„å†…ç½®æ¨¡æ¿'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ é›†æˆäº¤äº’åŠŸèƒ½å’Œå¯¼èˆª'}, ensure_ascii=False)}\n\n"
        
        html_content = await step4_generate_html(slides, narrations, book_data)
        
        # æ¸…ç†HTMLå†…å®¹
        html_content = clean_html_content(html_content)
        
        # éªŒè¯HTMLå†…å®¹å®Œæ•´æ€§
        if not html_content.strip().endswith('</html>'):
            raise ValueError("ç”Ÿæˆçš„HTMLå†…å®¹ä¸å®Œæ•´")
        
        yield f"data: {json.dumps({'log': f'  â”œâ”€ HTMLé•¿åº¦: {len(html_content)} å­—ç¬¦'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… HTMLç”Ÿæˆå®Œæˆ'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # ä¿å­˜æ–‡ä»¶
        yield f"data: {json.dumps({'log': 'ğŸ’¾ æ­£åœ¨ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶...'}, ensure_ascii=False)}\n\n"
        
        await save_generated_content(session_id, {
            'topic': topic,
            'book_data': book_data,
            'slides': slides,
            'narrations': narrations,
            'html_content': html_content
        })
        
        yield f"data: {json.dumps({'log': f'  â””â”€ âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°: outputs/{session_id}/'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # å¼€å§‹è¾“å‡ºç»“æœ
        yield f"data: {json.dumps({'log': 'ğŸ‰ ç”Ÿæˆå®Œæˆï¼å¼€å§‹è¾“å‡ºç»“æœ...'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.5)
        
        # æ£€æŸ¥HTMLå†…å®¹
        yield f"data: {json.dumps({'log': f'ğŸ” æ£€æŸ¥HTMLå†…å®¹: é•¿åº¦={len(html_content)}, ç±»å‹={type(html_content)}'}, ensure_ascii=False)}\n\n"
        
        if not html_content:
            yield f"data: {json.dumps({'log': 'âŒ HTMLå†…å®¹ä¸ºç©ºï¼'}, ensure_ascii=False)}\n\n"
            return
        
        # æŒ‰ç…§å‰ç«¯æœŸæœ›çš„æ ¼å¼è¾“å‡ºHTMLå†…å®¹
        yield f"data: {json.dumps({'log': 'ğŸ“¤ å¼€å§‹è¾“å‡ºHTMLå†…å®¹...'}, ensure_ascii=False)}\n\n"
        
        start_token = '```html\n'
        yield f"data: {json.dumps({'token': start_token}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'  â”œâ”€ å·²å‘é€å¼€å§‹æ ‡è®°: {repr(start_token)}'}, ensure_ascii=False)}\n\n"
        
        # åˆ†å—è¾“å‡ºHTMLå†…å®¹ï¼Œä½¿ç”¨è¾ƒå¤§çš„å—å¤§å°ç¡®ä¿å®Œæ•´æ€§
        chunk_size = 500
        chunk_count = 0
        for i in range(0, len(html_content), chunk_size):
            chunk = html_content[i:i+chunk_size]
            chunk_count += 1
            # ç¡®ä¿JSONå­—ç¬¦ä¸²æ­£ç¡®è½¬ä¹‰
            payload = json.dumps({"token": chunk}, ensure_ascii=False)
            yield f"data: {payload}\n\n"
            await asyncio.sleep(0.01)
        
        yield f"data: {json.dumps({'log': f'  â”œâ”€ å·²å‘é€ {chunk_count} ä¸ªHTMLå—'}, ensure_ascii=False)}\n\n"
        
        # è¾“å‡ºç»“æŸæ ‡è®°
        end_token = '\n```'
        yield f"data: {json.dumps({'token': end_token}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'  â””â”€ å·²å‘é€ç»“æŸæ ‡è®°: {repr(end_token)}'}, ensure_ascii=False)}\n\n"
        
        # æœ€ç»ˆå®Œæˆä¿¡æ¯
        yield f"data: {json.dumps({'log': 'ğŸŠ PPTç”Ÿæˆå®Œæˆï¼æ‚¨å¯ä»¥åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹æ•ˆæœ'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': 'âœ… å‡†å¤‡å‘é€DONEä¿¡å·'}, ensure_ascii=False)}\n\n"
        
        # å¦‚æœæœ‰ç”¨æˆ·IDï¼Œä¿å­˜PPTä¿¡æ¯åˆ°æ•°æ®åº“
        if user_id:
            try:
                await save_ppt_to_database(session_id, user_id, topic)
                yield f"data: {json.dumps({'log': 'ğŸ’¾ PPTä¿¡æ¯å·²ä¿å­˜åˆ°ä¸ªäººä¹¦æ¶'}, ensure_ascii=False)}\n\n"
            except Exception as e:
                yield f"data: {json.dumps({'log': f'âš ï¸ ä¿å­˜åˆ°ä¹¦æ¶å¤±è´¥: {str(e)}'}, ensure_ascii=False)}\n\n"
            
    except Exception as e:
        error_msg = f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        yield f"data: {json.dumps({'error': error_msg}, ensure_ascii=False)}\n\n"
        return

    yield f"data: {json.dumps({'log': 'ğŸ“¡ å‘é€DONEä¿¡å·'}, ensure_ascii=False)}\n\n"
    yield f'data: {json.dumps({"event":"[DONE]", "session_id": session_id, "output_path": f"outputs/{session_id}/"}, ensure_ascii=False)}\n\n'

# -----------------------------------------------------------------------
# 5. æ–‡ä»¶ä¿å­˜åŠŸèƒ½
# -----------------------------------------------------------------------
async def save_ppt_to_database(session_id: str, user_id: int, topic: str):
    """ä¿å­˜PPTä¿¡æ¯åˆ°æ•°æ®åº“"""
    try:
        # è¯»å–data.jsonæ–‡ä»¶è·å–è¯¦ç»†ä¿¡æ¯
        data_file = f"outputs/{session_id}/data.json"
        if os.path.exists(data_file):
            with open(data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            book_data = data.get('book_data', {})
            title = topic  # é»˜è®¤ä½¿ç”¨topic
            author = "æœªçŸ¥ä½œè€…"
            
            # é¦–å…ˆå°è¯•ä»book_dataä¸­æå–ä¹¦å
            if isinstance(book_data, dict):
                if 'title' in book_data:
                    title = book_data['title']
                elif 'book_title' in book_data:
                    title = book_data['book_title']
                elif 'raw_content' in book_data:
                    content_str = str(book_data['raw_content'])
                    # å°è¯•ä»å†…å®¹ä¸­æå–ä¹¦å
                    title_match = re.search(r'"title":\s*"([^"]+)"', content_str)
                    if title_match:
                        title = title_match.group(1)
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æ„åŒ–çš„ä¹¦åï¼Œå°è¯•ä»topicä¸­æå–
                        if 'ã€Š' in topic and 'ã€‹' in topic:
                            title_match = re.search(r'ã€Š([^ã€‹]+)ã€‹', topic)
                            if title_match:
                                title = title_match.group(1)
            
            # æå–ä½œè€…ä¿¡æ¯
            if isinstance(book_data, dict):
                if 'author' in book_data:
                    author = book_data['author']
                elif 'raw_content' in book_data:
                    content_str = str(book_data['raw_content'])
                    author_match = re.search(r'"author":\s*"([^"]+)"', content_str)
                    if author_match:
                        author = author_match.group(1)
            
            # æå–åˆ†ç±»ä¿¡æ¯
            category_id = book_data.get('category_id', 'literature')
            category_name = book_data.get('category_name', 'æ–‡å­¦ç±»')
            category_color = book_data.get('category_color', '#E74C3C')
            category_icon = book_data.get('category_icon', 'ğŸ“–')
            
            # è·å–å°é¢URL
            cover_url = None
            if 'cover_url' in book_data:
                cover_url = book_data['cover_url']
                
            # å¦‚æœå°é¢URLæ˜¯default_coverï¼Œç”Ÿæˆé»˜è®¤å°é¢
            if cover_url == "default_cover":
                cover_url = get_default_book_cover(title)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            from models import user_manager
            success = user_manager.add_ppt(
                session_id=session_id,
                user_id=user_id,
                title=title,
                author=author,
                cover_url=cover_url,
                category_id=category_id,
                category_name=category_name,
                category_color=category_color,
                category_icon=category_icon
            )
            
            if success:
                print(f"âœ… PPTå·²ä¿å­˜åˆ°ç”¨æˆ·æ•°æ®åº“: {title}")
            else:
                print(f"âŒ ä¿å­˜PPTåˆ°æ•°æ®åº“å¤±è´¥: {title}")
                
    except Exception as e:
        print(f"ä¿å­˜PPTåˆ°æ•°æ®åº“æ—¶å‡ºé”™: {e}")

async def save_generated_content(session_id: str, content: dict):
    """
    ä¿å­˜ç”Ÿæˆçš„å†…å®¹åˆ°æ–‡ä»¶ç³»ç»Ÿ
    """
    import os
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = f"outputs/{session_id}"
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜HTMLæ–‡ä»¶
    html_file = os.path.join(output_dir, "presentation.html")
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(content['html_content'])
    
    # ä¿å­˜JSONæ•°æ®æ–‡ä»¶
    data_file = os.path.join(output_dir, "data.json")
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump({
            'topic': content['topic'],
            'book_data': content['book_data'],
            'slides': content['slides'],
            'narrations': content['narrations']
        }, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜READMEæ–‡ä»¶
    readme_file = os.path.join(output_dir, "README.md")
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(f"""# ä¹¦ç±ä»‹ç»PPT - {content['topic']}

## æ–‡ä»¶è¯´æ˜
- `presentation.html` - å®Œæ•´çš„PPTæ¼”ç¤ºæ–‡ä»¶ï¼ˆå¯ç›´æ¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼‰
- `data.json` - ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ•°æ®
- `README.md` - æœ¬è¯´æ˜æ–‡ä»¶

## ä½¿ç”¨æ–¹æ³•
1. ç›´æ¥åŒå‡» `presentation.html` åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
2. ä½¿ç”¨å·¦å³ç®­å¤´é”®æˆ–ç‚¹å‡»å¯¼èˆªç‚¹åˆ‡æ¢é¡µé¢
3. æŸ¥çœ‹åº•éƒ¨è§£è¯´è¯é¢æ¿äº†è§£è¯¦ç»†å†…å®¹

## ç”Ÿæˆæ—¶é—´
{datetime.now(shanghai_tz).strftime("%Y-%m-%d %H:%M:%S")}

## ä¼šè¯ID
{session_id}
""")
    
    # æ·»åŠ åˆ°åˆ†ç±»æ•°æ®åº“
    try:
        book_data = content.get('book_data', {})
        topic = content.get('topic', '')
        
        # æå–ä½œè€…ä¿¡æ¯
        author = "æœªçŸ¥ä½œè€…"
        if isinstance(book_data, dict):
            # å°è¯•ä»ä¸åŒå­—æ®µæå–ä½œè€…
            if 'author' in book_data:
                author = book_data['author']
            elif 'raw_content' in book_data:
                content_str = str(book_data['raw_content'])
                author_match = re.search(r'"author":\s*"([^"]+)"', content_str)
                if author_match:
                    author = author_match.group(1)
        
        # æå–åˆ†ç±»ä¿¡æ¯
        category_info = {
            'category_id': book_data.get('category_id', 'literature'),
            'category_name': book_data.get('category_name', 'æ–‡å­¦ç±»'),
            'category_color': book_data.get('category_color', '#E74C3C'),
            'category_icon': book_data.get('category_icon', 'ğŸ“–')
        }
        
        # æ·»åŠ åˆ°åˆ†ç±»æ•°æ®åº“
        add_book_to_category(topic, author, category_info, session_id)
        print(f"âœ… å·²æ·»åŠ åˆ°åˆ†ç±»æ•°æ®åº“: ã€Š{topic}ã€‹- {category_info['category_name']}")
        
    except Exception as e:
        print(f"âš ï¸ æ·»åŠ åˆ°åˆ†ç±»æ•°æ®åº“å¤±è´¥: {e}")
    
    print(f"å†…å®¹å·²ä¿å­˜åˆ°: {output_dir}/")
    return output_dir

def clean_html_content(html_content: str) -> str:
    """
    æ¸…ç†HTMLå†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°å’Œå¤šä½™å†…å®¹
    """
    import re
    
    # ç§»é™¤å¼€å¤´çš„ ```html æ ‡è®°
    html_content = re.sub(r'^```html\s*\n?', '', html_content, flags=re.MULTILINE)
    
    # ç§»é™¤ç»“å°¾çš„ ``` æ ‡è®°å’Œåç»­çš„æ‰€æœ‰å†…å®¹
    html_content = re.sub(r'\n?```[\s\S]*$', '', html_content)
    
    # ç¡®ä¿æ–‡ä»¶ä»¥ </html> ç»“å°¾
    if not html_content.strip().endswith('</html>'):
        # æ‰¾åˆ°æœ€åä¸€ä¸ª </html> æ ‡ç­¾çš„ä½ç½®
        last_html_match = None
        for match in re.finditer(r'</html>', html_content):
            last_html_match = match
        
        if last_html_match:
            # æˆªå–åˆ°æœ€åä¸€ä¸ª </html> æ ‡ç­¾
            html_content = html_content[:last_html_match.end()]
    
    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    html_content = re.sub(r'\n\s*\n\s*\n', '\n\n', html_content)
    
    # ç¡®ä¿æ–‡ä»¶ä»¥æ¢è¡Œç¬¦ç»“å°¾
    if not html_content.endswith('\n'):
        html_content += '\n'
    
    return html_content

def generate_reliable_ppt_html_internal(slides, narrations, book_data, book_title=None):
    """ç”Ÿæˆä¼˜åŒ–çš„æ¯›ç»ç’ƒé£æ ¼PPT HTML"""
    
    print(f"DEBUG: generate_reliable_ppt_html_internal å¼€å§‹æ‰§è¡Œ")
    print(f"DEBUG: slides: {type(slides)}, narrations: {type(narrations)}")
    print(f"DEBUG: ä¼ å…¥çš„book_titleå‚æ•°: {book_title}")
    
    # è§£æbook_data
    parsed_book_data = parse_ai_response(book_data)
    
    # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„book_titleå‚æ•°ï¼Œå¦åˆ™å°è¯•ä»book_dataä¸­æå–
    if book_title:
        final_book_title = book_title
        print(f"DEBUG: ä½¿ç”¨ä¼ å…¥çš„book_title: {final_book_title}")
    else:
        final_book_title = extract_book_title(parsed_book_data)
        print(f"DEBUG: ä»book_dataæå–çš„book_title: {final_book_title}")
    
    # å¦‚æœè¿˜æ˜¯"æœªçŸ¥ä¹¦ç±"ï¼Œå°è¯•ä»book_dataçš„å…¶ä»–å­—æ®µè·å–
    if final_book_title == "æœªçŸ¥ä¹¦ç±" and isinstance(book_data, dict):
        if 'title' in book_data:
            final_book_title = book_data['title']
        elif 'book_title' in book_data:
            final_book_title = book_data['book_title']
    
    print(f"DEBUG: æœ€ç»ˆä½¿ç”¨çš„book_title: {final_book_title}")
    
    # è·å–ä¹¦ç±å°é¢
    cover_url = ""
    if isinstance(book_data, dict):
        cover_url = book_data.get('cover_url', '')
    if not cover_url and isinstance(parsed_book_data, dict):
        cover_url = parsed_book_data.get('cover_url', '')
    
    # è§£æslidesæ•°æ®
    parsed_slides = parse_ai_response(slides)
    processed_slides = process_slides_data(parsed_slides, final_book_title)
    print(f"DEBUG: processed_slides é•¿åº¦: {len(processed_slides)}")
    
    # è§£ænarrationsæ•°æ®
    parsed_narrations = parse_ai_response(narrations)
    processed_narrations = process_narrations_data(parsed_narrations, final_book_title)
    print(f"DEBUG: processed_narrations é•¿åº¦: {len(processed_narrations)}")
    
    # ç¡®ä¿slideså’Œnarrationsæ•°é‡åŒ¹é…
    while len(processed_narrations) < len(processed_slides):
        processed_narrations.append(f'è¿™æ˜¯ç¬¬{len(processed_narrations)+1}é¡µçš„è§£è¯´å†…å®¹')
    
    # ç”Ÿæˆè§£è¯´è¯æ•°æ®ï¼ˆæ¯é¡µæŒ‰å¥å­åˆ†å‰²ï¼‰
    narration_data = []
    for i, narration in enumerate(processed_narrations):
        sentences = []
        timings = []
        
        # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²å¥å­
        text = str(narration).strip()
        sentence_list = []
        for sent in text.split('ã€‚'):
            sent = sent.strip()
            if sent:
                sentence_list.append(sent + 'ã€‚')
        
        # å¦‚æœæ²¡æœ‰æŒ‰å¥å·åˆ†å‰²æˆåŠŸï¼Œå°è¯•å…¶ä»–æ ‡ç‚¹
        if len(sentence_list) <= 1:
            for sent in text.split('ï¼'):
                sent = sent.strip()
                if sent:
                    sentence_list.append(sent + 'ï¼')
        
        if len(sentence_list) <= 1:
            for sent in text.split('ï¼Ÿ'):
                sent = sent.strip()
                if sent:
                    sentence_list.append(sent + 'ï¼Ÿ')
        
        # å¦‚æœè¿˜æ˜¯åˆ†å‰²ä¸äº†ï¼Œå°±ç”¨æ•´æ®µæ–‡å­—
        if len(sentence_list) <= 1:
            sentence_list = [text]
        
        # ç”Ÿæˆæ—¶é—´ç‚¹ï¼ˆæ¯å¥è¯é—´éš”6ç§’ï¼‰
        for j, sentence in enumerate(sentence_list):
            sentences.append(sentence)
            timings.append(j * 6)
        
        narration_data.append({
            "sentences": sentences,
            "timings": timings
        })
    
    # ç”Ÿæˆå¹»ç¯ç‰‡HTML
    slides_html = ""
    for i, slide in enumerate(processed_slides):
        active_class = "active" if i == 0 else ""
        # è·å–å¯¹åº”çš„è§£è¯´è¯ï¼Œå¹¶è¿›è¡ŒHTMLè½¬ä¹‰
        narration_text = processed_narrations[i] if i < len(processed_narrations) else ""
        # HTMLè½¬ä¹‰å¤„ç†å¼•å·å’Œç‰¹æ®Šå­—ç¬¦
        narration_text = str(narration_text).replace('"', '&quot;').replace('\n', ' ').replace('\r', '')
        
        if i == 0:
            # ä¹¦ç±æ ‡é¢˜é¡µ - ä¸“é—¨å±•ç¤ºä¹¦å
            slides_html += f'''
                <div class="slide {active_class}" data-speech="{narration_text}">
                    <div style="text-align: center; padding: 2rem;">
                        <h1 style="font-size: 3rem; font-weight: bold; margin-bottom: 1rem; color: #1D1D1F;">{final_book_title}</h1>
                        <div style="width: 80px; height: 3px; background: linear-gradient(to right, #667eea, #764ba2); margin: 2rem auto; border-radius: 2px;"></div>
                        <p style="font-size: 1.2rem; color: #666; font-style: italic;">æ¬¢è¿æ¥åˆ°æœ¬ä¹¦çš„ç²¾å½©è§£è¯»</p>
                    </div>
                </div>'''
        else:
            # å†…å®¹é¡µ
            content = slide.get('content', '').replace('\n', '<br>')
            slides_html += f'''
                <div class="slide {active_class}" data-speech="{narration_text}">
                    <h2>{slide.get('title', f'ç¬¬{i+1}é¡µ')}</h2>
                    <p>{content}</p>
                </div>'''
    
    
    # ç”Ÿæˆè§£è¯´è¯JavaScriptæ•°æ®
    narration_data_js = "["
    for i, data in enumerate(narration_data):
        if i > 0:
            narration_data_js += ","
        narration_data_js += "\n        {\n"
        narration_data_js += f'            "sentences": {json.dumps(data["sentences"], ensure_ascii=False)},\n'
        narration_data_js += f'            "timings": {data["timings"]}\n'
        narration_data_js += "        }"
    narration_data_js += "\n    ]"
    
    html_template = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{final_book_title} - Bookagent æ™ºèƒ½æ¼”ç¤º</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-font-smoothing: antialiased;
        }}

        body {{
            font-family: "Helvetica Neue", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif;
            background: linear-gradient(135deg, 
                #667eea 0%, 
                #764ba2 25%, 
                #f093fb 50%, 
                #f5576c 75%, 
                #4facfe 100%);
            background-size: 400% 400%;
            animation: gradientShift 10s ease infinite;
            min-height: 100vh;
            overflow: hidden;
            color: #333;
        }}

        @keyframes gradientShift {{
            0%, 100% {{ background-position: 0% 50%; }}
            50% {{ background-position: 100% 50%; }}
        }}

        .presentation-container {{
            display: flex;
            height: 100vh;
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
        }}

        /* å·¦ä¾§å¯¼èˆª */
        .nav-sidebar {{
            width: 250px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(30px);
            -webkit-backdrop-filter: blur(30px);
            border-right: 1px solid rgba(255, 255, 255, 0.2);
            padding: 20px;
            display: flex;
            flex-direction: column;
            gap: 15px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }}

        .logo-section {{
            text-align: center;
            padding: 20px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.2);
            margin-bottom: 20px;
        }}

        .logo-title {{
            font-size: 24px;
            font-weight: bold;
            color: white;
            text-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
            background: linear-gradient(45deg, #fff, #f0f0f0);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}

        .nav-button {{
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 12px;
            padding: 15px 20px;
            color: white;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            text-align: center;
            font-size: 16px;
            font-weight: 500;
            text-shadow: 0 1px 3px rgba(0, 0, 0, 0.3);
            position: relative;
            overflow: hidden;
        }}

        .nav-button:hover {{
            background: rgba(255, 255, 255, 0.25);
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.2);
        }}

        .nav-button.playing {{
            background: linear-gradient(135deg, #667eea, #764ba2);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }}

        .slide-counter {{
            background: rgba(255, 255, 255, 0.1);
            border-radius: 8px;
            padding: 12px;
            text-align: center;
            color: white;
            font-size: 14px;
            margin-top: auto;
        }}

        /* ä¸»å†…å®¹åŒºåŸŸ */
        .main-content {{
            flex: 1;
            display: flex;
            flex-direction: column;
            position: relative;
        }}

        .slide-container {{
            flex: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 40px;
            position: relative;
        }}

        .slide {{
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3);
            padding: 60px;
            max-width: 900px;
            width: 100%;
            min-height: 600px;
            display: none;
            flex-direction: column;
            justify-content: center;
            position: relative;
            animation: slideIn 0.6s cubic-bezier(0.4, 0, 0.2, 1);
        }}

        .slide.active {{
            display: flex;
        }}

        @keyframes slideIn {{
            from {{
                opacity: 0;
                transform: translateY(30px) scale(0.95);
            }}
            to {{
                opacity: 1;
                transform: translateY(0) scale(1);
            }}
        }}

        .slide h1 {{
            font-size: 2.5em;
            margin-bottom: 30px;
            color: #2c3e50;
            text-align: center;
            line-height: 1.3;
            font-weight: 600;
        }}

        .slide h2 {{
            font-size: 2em;
            margin-bottom: 25px;
            color: #34495e;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }}

        .slide p {{
            font-size: 1.2em;
            line-height: 1.8;
            margin-bottom: 20px;
            color: #555;
            text-align: justify;
        }}

        .slide ul {{
            margin: 20px 0;
            padding-left: 30px;
        }}

        .slide li {{
            font-size: 1.1em;
            line-height: 1.7;
            margin-bottom: 12px;
            color: #666;
        }}

        /* å³ä¾§å¯¼èˆª */
        .nav-right {{
            width: 120px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            gap: 20px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(30px);
            -webkit-backdrop-filter: blur(30px);
            border-left: 1px solid rgba(255, 255, 255, 0.2);
        }}

        .nav-arrow {{
            width: 60px;
            height: 60px;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            color: white;
            font-size: 20px;
            margin: 0 auto;
        }}

        .nav-arrow:hover {{
            background: rgba(255, 255, 255, 0.25);
            transform: scale(1.1);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.2);
        }}

        .nav-arrow:disabled {{
            opacity: 0.3;
            cursor: not-allowed;
            transform: none;
        }}

        /* å­—å¹•åŒºåŸŸ */
        .narration-display {{
            background: rgba(0, 0, 0, 0.8);
            backdrop-filter: blur(15px);
            -webkit-backdrop-filter: blur(15px);
            color: #FFD700;
            padding: 25px 40px;
            text-align: center;
            font-size: 18px;
            line-height: 1.6;
            min-height: 80px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            text-shadow: 0 1px 3px rgba(0, 0, 0, 0.5);
        }}

        .sentence {{
            opacity: 0;
            transition: opacity 0.8s ease-in-out;
            font-weight: 500;
        }}

        .sentence.active {{
            opacity: 1;
        }}

        /* å“åº”å¼è®¾è®¡ */
        @media (max-width: 1024px) {{
            .nav-sidebar {{
                width: 200px;
            }}
            
            .slide {{
                padding: 40px;
                max-width: 700px;
            }}
        }}

        @media (max-width: 768px) {{
            .presentation-container {{
                flex-direction: column;
            }}
            
            .nav-sidebar {{
                width: 100%;
                height: auto;
                flex-direction: row;
                justify-content: space-around;
                padding: 15px;
            }}
            
            .nav-right {{
                width: 100%;
                flex-direction: row;
                justify-content: center;
                height: auto;
                padding: 15px;
            }}
            
            .slide {{
                padding: 30px;
                margin: 20px;
            }}
        }}
    </style>
</head>
<body>
    <div class="presentation-container">
        <!-- å·¦ä¾§å¯¼èˆªæ  -->
        <div class="nav-sidebar">
            <div class="logo-section">
                <div class="logo-title">Bookagent</div>
            </div>
            
            <button id="playPauseButton" class="nav-button" onclick="toggleAudio()">
                ğŸ”Š æ’­æ”¾è§£è¯´
            </button>
            
            <button id="backButton" class="nav-button" onclick="goBack()" style="background: rgba(255, 255, 255, 0.2);">
                â† è¿”å›ä¸»é¡µ
            </button>
            
            <div class="slide-counter">
                <div id="slideCounter">ç¬¬ 1 é¡µ / {len(processed_slides)} é¡µ</div>
            </div>
        </div>

        <!-- ä¸»å†…å®¹åŒºåŸŸ -->
        <div class="main-content">
            <div class="slide-container">
                {slides_html}
            </div>

            <!-- å­—å¹•æ˜¾ç¤ºåŒºåŸŸ -->
            <div class="narration-display">
                <div id="currentNarration">ç‚¹å‡»"æ’­æ”¾è§£è¯´"å¼€å§‹è‡ªåŠ¨æ’­æ”¾æ¼”ç¤º</div>
            </div>
        </div>

        <!-- å³ä¾§å¯¼èˆª -->
        <div class="nav-right">
            <button class="nav-arrow" id="prevBtn" onclick="prevSlide()">â®</button>
            <button class="nav-arrow" id="nextBtn" onclick="nextSlide()">â¯</button>
        </div>
    </div>

    <!-- éŸ³é¢‘æ’­æ”¾å™¨ -->
    <audio id="audioPlayer" preload="auto"></audio>

    <script>
        // å…¨å±€å˜é‡
        let currentSlide = 0;
        let totalSlides = {len(processed_slides)};
        let isAutoPlaying = false;
        let isPlaying = false;
        let sentenceTimers = [];

        // è§£è¯´è¯æ•°æ®
        const narrationData = {narration_data_js};

        // åˆå§‹åŒ–
        document.addEventListener('DOMContentLoaded', function() {{
            updateSlideCounter();
            updateNavigationButtons();
        }});

        // éŸ³é¢‘æ’­æ”¾åŠŸèƒ½
        function toggleAudio() {{
            const playPauseButton = document.getElementById('playPauseButton');
            
            if (isAutoPlaying) {{
                // åœæ­¢è‡ªåŠ¨æ’­æ”¾
                stopAutoPlay();
                playPauseButton.textContent = 'ğŸ”Š æ’­æ”¾è§£è¯´';
                playPauseButton.classList.remove('playing');
            }} else {{
                // å¼€å§‹è‡ªåŠ¨æ’­æ”¾æ•´ä¸ªPPT
                startAutoPlay();
                playPauseButton.textContent = 'â¸ï¸ åœæ­¢æ’­æ”¾';
                playPauseButton.classList.add('playing');
            }}
        }}
        
        function startAutoPlay() {{
            isAutoPlaying = true;
            // ä»å½“å‰é¡µå¼€å§‹æ’­æ”¾ï¼Œè€Œä¸æ˜¯é‡ç½®åˆ°ç¬¬ä¸€é¡µ
            // currentSlide ä¿æŒå½“å‰å€¼
            showSlide(currentSlide);
            playCurrentSlide();
        }}
        
        function stopAutoPlay() {{
            isAutoPlaying = false;
            isPlaying = false;
            const audioPlayer = document.getElementById('audioPlayer');
            if (audioPlayer) {{
                audioPlayer.pause();
                audioPlayer.currentTime = 0;
            }}
            clearSentenceTimers();
            resetNarrationDisplay();
        }}
        
        function playCurrentSlide() {{
            if (!isAutoPlaying) return;
            
            const audioPlayer = document.getElementById('audioPlayer');
            const sessionId = window.location.pathname.split('/')[2]; // ä»URLä¸­æå–session_id
            const slideNumber = (currentSlide + 1).toString().padStart(2, '0');
            const audioPath = `/ppt_audio/${{sessionId}}_slide_${{slideNumber}}.mp3`;
            
            audioPlayer.src = audioPath;
            audioPlayer.play().then(() => {{
                isPlaying = true;
                startSentenceDisplay();
            }}).catch((error) => {{
                console.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error);
                // å¦‚æœéŸ³é¢‘æ’­æ”¾å¤±è´¥ï¼Œä»ç„¶æ˜¾ç¤ºå­—å¹•å¹¶åœ¨5ç§’ååˆ‡æ¢åˆ°ä¸‹ä¸€é¡µ
                startSentenceDisplay();
                setTimeout(() => {{
                    if (isAutoPlaying) {{
                        goToNextSlide();
                    }}
                }}, 5000);
            }});
        }}

        // å¯¼èˆªåŠŸèƒ½
        function nextSlide() {{
            if (isAutoPlaying) {{
                stopAutoPlay();
                const playPauseButton = document.getElementById('playPauseButton');
                playPauseButton.textContent = 'ğŸ”Š æ’­æ”¾è§£è¯´';
                playPauseButton.classList.remove('playing');
            }}
            goToNextSlide();
        }}
        
        function prevSlide() {{
            if (isAutoPlaying) {{
                stopAutoPlay();
                const playPauseButton = document.getElementById('playPauseButton');
                playPauseButton.textContent = 'ğŸ”Š æ’­æ”¾è§£è¯´';
                playPauseButton.classList.remove('playing');
            }}
            goToPrevSlide();
        }}
        
        function goToNextSlide() {{
            if (currentSlide < totalSlides - 1) {{
                currentSlide++;
                showSlide(currentSlide);
                if (isAutoPlaying) {{
                    setTimeout(() => playCurrentSlide(), 500);
                }}
            }} else if (isAutoPlaying) {{
                // åˆ°è¾¾æœ€åä¸€é¡µï¼Œåœæ­¢è‡ªåŠ¨æ’­æ”¾
                stopAutoPlay();
                const playPauseButton = document.getElementById('playPauseButton');
                playPauseButton.textContent = 'ğŸ”Š æ’­æ”¾è§£è¯´';
                playPauseButton.classList.remove('playing');
            }}
        }}
        
        function goToPrevSlide() {{
            if (currentSlide > 0) {{
                currentSlide--;
                showSlide(currentSlide);
                if (isAutoPlaying) {{
                    setTimeout(() => playCurrentSlide(), 500);
                }}
            }}
        }}

        function showSlide(slideIndex) {{
            const slides = document.querySelectorAll('.slide');
            
            // éšè—æ‰€æœ‰å¹»ç¯ç‰‡
            slides.forEach(slide => slide.classList.remove('active'));
            
            // æ˜¾ç¤ºç›®æ ‡å¹»ç¯ç‰‡
            if (slides[slideIndex]) {{
                slides[slideIndex].classList.add('active');
                currentSlide = slideIndex;
            }}
            
            updateSlideCounter();
            updateNavigationButtons();
            if (!isAutoPlaying) {{
                resetNarrationDisplay();
            }}
        }}

        function updateSlideCounter() {{
            const counter = document.getElementById('slideCounter');
            if (counter) {{
                counter.textContent = `ç¬¬ ${{currentSlide + 1}} é¡µ / ${{totalSlides}} é¡µ`;
            }}
        }}

        function updateNavigationButtons() {{
            const prevBtn = document.getElementById('prevBtn');
            const nextBtn = document.getElementById('nextBtn');
            
            if (prevBtn) {{
                prevBtn.disabled = currentSlide === 0;
            }}
            if (nextBtn) {{
                nextBtn.disabled = currentSlide === totalSlides - 1;
            }}
        }}

        // å­—å¹•æ˜¾ç¤ºåŠŸèƒ½
        function startSentenceDisplay() {{
            const slideData = narrationData[currentSlide];
            if (!slideData) return;
            
            clearSentenceTimers();
            
            slideData.sentences.forEach((sentence, index) => {{
                const delay = slideData.timings[index] * 1000;
                const timer = setTimeout(() => {{
                    if (isAutoPlaying || isPlaying) {{
                        displaySentence(sentence);
                    }}
                }}, delay);
                sentenceTimers.push(timer);
            }});

            // éŸ³é¢‘ç»“æŸåè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€é¡µ
            const audioPlayer = document.getElementById('audioPlayer');
            audioPlayer.onended = () => {{
                if (isAutoPlaying) {{
                    setTimeout(() => goToNextSlide(), 1000);
                }}
            }};
        }}

        function displaySentence(sentence) {{
            const narrationDiv = document.getElementById('currentNarration');
            if (narrationDiv) {{
                narrationDiv.innerHTML = `<span class="sentence active">${{sentence}}</span>`;
            }}
        }}

        function clearSentenceTimers() {{
            sentenceTimers.forEach(timer => clearTimeout(timer));
            sentenceTimers = [];
        }}

        function resetNarrationDisplay() {{
            const narrationDiv = document.getElementById('currentNarration');
            if (narrationDiv) {{
                narrationDiv.innerHTML = 'ç‚¹å‡»"æ’­æ”¾è§£è¯´"å¼€å§‹è‡ªåŠ¨æ’­æ”¾æ¼”ç¤º';
            }}
        }}

        // é”®ç›˜å¯¼èˆª
        document.addEventListener('keydown', function(event) {{
            if (event.key === 'ArrowLeft') {{
                prevSlide();
            }} else if (event.key === 'ArrowRight') {{
                nextSlide();
            }} else if (event.key === ' ') {{
                event.preventDefault();
                toggleAudio();
            }}
        }});

        // è¿”å›ä¸»é¡µåŠŸèƒ½
        function goBack() {{
            // è¿”å›åˆ°ä¸»åº”ç”¨é¡µé¢
            window.location.href = '/';
        }}
    </script>
</body>
</html>'''
    
    return html_template

def parse_ai_response(data):
    """è§£æAIè¿”å›çš„æ•°æ®ï¼Œå¤„ç†raw_contentæ ¼å¼"""
    if isinstance(data, dict) and 'raw_content' in data:
        raw_content = data['raw_content']
        if isinstance(raw_content, str):
            # å°è¯•ä»JSONä»£ç å—ä¸­æå–æ•°æ®
            import re
            json_match = re.search(r'```json\s*\n(.*?)\n```', raw_content, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group(1))
                except:
                    pass
            # å°è¯•ç›´æ¥è§£æJSON
            try:
                return json.loads(raw_content)
            except:
                pass
        return raw_content
    elif isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict) and 'raw_content' in data[0]:
        # å¤„ç†åˆ—è¡¨æ ¼å¼çš„æ•°æ®
        return parse_ai_response(data[0])
    return data

def extract_book_title(book_data):
    """ä»ä¹¦ç±æ•°æ®ä¸­æå–æ ‡é¢˜"""
    if isinstance(book_data, dict):
        # ç›´æ¥æŸ¥æ‰¾titleå­—æ®µ
        if 'book_title' in book_data:
            return book_data['book_title']
        elif 'title' in book_data:
            return book_data['title']
        # æ£€æŸ¥raw_contentå­—æ®µ
        elif 'raw_content' in book_data:
            raw_content = book_data['raw_content']
            if isinstance(raw_content, str):
                import re
                # å°è¯•å¤šç§æ¨¡å¼åŒ¹é…
                patterns = [
                    r'"book_title":\s*"([^"]+)"',
                    r'"title":\s*"([^"]+)"',
                    r'ã€Š([^ã€‹]+)ã€‹',  # åŒ¹é…ä¹¦åå·
                    r'"([^"]*)"'  # æœ€åå°è¯•åŒ¹é…ä»»ä½•å¼•å·å†…å®¹
                ]
                for pattern in patterns:
                    match = re.search(pattern, raw_content)
                    if match:
                        title = match.group(1).strip()
                        if title and title != "æœªçŸ¥ä¹¦ç±":
                            return title
    
    # ä»å­—ç¬¦ä¸²ä¸­æå–
    if isinstance(book_data, str):
        import re
        patterns = [
            r'"(?:book_title|title)":\s*"([^"]+)"',
            r'ã€Š([^ã€‹]+)ã€‹',
            r'"([^"]*)"'
        ]
        for pattern in patterns:
            match = re.search(pattern, book_data)
            if match:
                title = match.group(1).strip()
                if title and title != "æœªçŸ¥ä¹¦ç±":
                    return title
    
    return "æœªçŸ¥ä¹¦ç±"

def process_slides_data(slides_data, book_title):
    """å¤„ç†å¹»ç¯ç‰‡æ•°æ®"""
    processed_slides = []
    
    if isinstance(slides_data, list) and len(slides_data) > 0:
        for i, slide in enumerate(slides_data):
            if isinstance(slide, dict):
                processed_slides.append({
                    'title': slide.get('title', f'ç¬¬{i+1}é¡µ'),
                    'subtitle': slide.get('subtitle', ''),
                    'content': slide.get('main_content', slide.get('content', ''))
                })
            else:
                processed_slides.append({
                    'title': f'ç¬¬{i+1}é¡µ',
                    'subtitle': '',
                    'content': str(slide)
                })
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å¹»ç¯ç‰‡
    if not processed_slides:
        processed_slides = [
            {'title': book_title, 'subtitle': 'å¼€åœºä»‹ç»', 'content': f'æ¬¢è¿æ¥åˆ°ã€Š{book_title}ã€‹çš„åˆ†äº«'},
            {'title': 'ä½œè€…ä»‹ç»', 'subtitle': 'äº†è§£ä½œè€…', 'content': f'è®©æˆ‘ä»¬äº†è§£ã€Š{book_title}ã€‹çš„ä½œè€…'},
            {'title': 'æ ¸å¿ƒå†…å®¹', 'subtitle': 'ä¸»è¦è§‚ç‚¹', 'content': f'ã€Š{book_title}ã€‹çš„æ ¸å¿ƒå†…å®¹å’Œä¸»è¦è§‚ç‚¹'},
            {'title': 'æ·±åº¦è§£è¯»', 'subtitle': 'ç²¾å½©ç‰‡æ®µ', 'content': f'ã€Š{book_title}ã€‹ä¸­çš„ç²¾å½©ç‰‡æ®µå’Œæ·±åº¦æ€è€ƒ'},
            {'title': 'ç°å®æ„ä¹‰', 'subtitle': 'å½“ä»£ä»·å€¼', 'content': f'ã€Š{book_title}ã€‹å¯¹å½“ä»£è¯»è€…çš„æ„ä¹‰å’Œä»·å€¼'},
            {'title': 'æ€»ç»“', 'subtitle': 'ç»“æŸè¯­', 'content': f'æ„Ÿè°¢æ‚¨è§‚çœ‹ã€Š{book_title}ã€‹çš„ä»‹ç»ï¼Œå¸Œæœ›è¿™æœ¬ä¹¦èƒ½ç»™æ‚¨å¸¦æ¥å¯å‘'}
        ]
    
    return processed_slides

def process_narrations_data(narrations_data, book_title):
    """å¤„ç†è§£è¯´è¯æ•°æ®"""
    processed_narrations = []
    
    if isinstance(narrations_data, list) and len(narrations_data) > 0:
        for narration in narrations_data:
            if isinstance(narration, dict):
                # æå–ä¸»è¦è§£è¯´å†…å®¹
                content = (narration.get('main_narration', '') or 
                          narration.get('opening', '') or 
                          narration.get('content', '') or
                          str(narration))
                processed_narrations.append(content)
            else:
                processed_narrations.append(str(narration))
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤è§£è¯´è¯
    if not processed_narrations:
        processed_narrations = [
            f'æ¬¢è¿æ¥åˆ°ã€Š{book_title}ã€‹çš„ä»‹ç»ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢è¿™æœ¬ä¹¦çš„ç²¾å½©å†…å®¹',
            f'è®©æˆ‘ä»¬äº†è§£ã€Š{book_title}ã€‹çš„ä½œè€…ï¼Œä»¥åŠåˆ›ä½œè¿™æœ¬ä¹¦çš„èƒŒæ™¯å’ŒåŠ¨æœº',
            f'ã€Š{book_title}ã€‹åŒ…å«äº†ä¸°å¯Œçš„å†…å®¹å’Œæ·±åˆ»çš„æ€è€ƒï¼Œå€¼å¾—æˆ‘ä»¬ä»”ç»†å“å‘³',
            f'é€šè¿‡æ·±åº¦è§£è¯»ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°ç†è§£ã€Š{book_title}ã€‹æƒ³è¦ä¼ è¾¾çš„ä¿¡æ¯',
            f'ã€Š{book_title}ã€‹ä¸ä»…æ˜¯ä¸€æœ¬ä¹¦ï¼Œæ›´æ˜¯å¯¹ç°å®ç”Ÿæ´»çš„æ·±åˆ»åæ€',
            f'æ„Ÿè°¢æ‚¨è§‚çœ‹ã€Š{book_title}ã€‹çš„ä»‹ç»ï¼Œå¸Œæœ›è¿™æœ¬ä¹¦èƒ½ç»™æ‚¨å¸¦æ¥æ”¶è·å’Œå¯å‘'
        ]
    
    return processed_narrations

def get_fallback_book_data(topic: str) -> dict:
    """å½“APIé…é¢ç”¨å®Œæ—¶ï¼Œè¿”å›é»˜è®¤çš„ä¹¦ç±æ•°æ®"""
    return {
        "raw_content": f'''```json
{{
  "book_title": "{topic}",
  "author": "çŸ¥åä½œè€…",
  "summary": [
    "ã€Š{topic}ã€‹æ˜¯ä¸€éƒ¨æ·±å—è¯»è€…å–œçˆ±çš„ç»å…¸ä½œå“ã€‚",
    "è¿™æœ¬ä¹¦é€šè¿‡ç”ŸåŠ¨çš„æ•…äº‹æƒ…èŠ‚ï¼Œå±•ç°äº†æ·±åˆ»çš„äººç”Ÿå“²ç†ã€‚",
    "ä½œå“å…·æœ‰å¾ˆå¼ºçš„ç°å®æ„ä¹‰å’Œæ•™è‚²ä»·å€¼ã€‚"
  ],
  "core_ideas": [
    "æ¢è®¨äººç”Ÿçš„æ„ä¹‰å’Œä»·å€¼",
    "å±•ç°äººæ€§çš„å¤æ‚ä¸ç¾å¥½",
    "ä¼ è¾¾ç§¯æå‘ä¸Šçš„äººç”Ÿæ€åº¦",
    "åæ€ç¤¾ä¼šç°è±¡å’Œäººé™…å…³ç³»"
  ],
  "target_audience": [
    "æ–‡å­¦çˆ±å¥½è€…",
    "é’å¹´è¯»è€…",
    "æ•™è‚²å·¥ä½œè€…",
    "å¯¹äººç”Ÿå“²ç†æ„Ÿå…´è¶£çš„è¯»è€…"
  ],
  "value_and_significance": [
    "å…·æœ‰é‡è¦çš„æ–‡å­¦ä»·å€¼å’Œç¤¾ä¼šæ„ä¹‰",
    "èƒ½å¤Ÿå¯å‘è¯»è€…æ€è€ƒäººç”Ÿ",
    "å¯¹å½“ä»£æ–‡å­¦å‘å±•æœ‰é‡è¦å½±å“"
  ],
  "ppt_key_chapters_themes": [
    "ä½œå“èƒŒæ™¯ä¸åˆ›ä½œåŠ¨æœº",
    "ä¸»è¦äººç‰©å½¢è±¡åˆ†æ",
    "æ ¸å¿ƒä¸»é¢˜æ€æƒ³",
    "è‰ºæœ¯ç‰¹è‰²ä¸è¡¨ç°æ‰‹æ³•",
    "ç°å®æ„ä¹‰ä¸å¯ç¤º",
    "è¯»åæ„Ÿæ‚Ÿä¸æ€è€ƒ"
  ]
}}
```'''
    }

def get_fallback_slides_data(book_title: str) -> list:
    """å½“APIé…é¢ç”¨å®Œæ—¶ï¼Œè¿”å›é»˜è®¤çš„å¹»ç¯ç‰‡æ•°æ®"""
    return [{
        "raw_content": f'''```json
[
  {{
    "slide_number": 1,
    "slide_type": "opening",
    "title": "{book_title}",
    "subtitle": "ç»å…¸ä½œå“åˆ†äº«",
    "main_content": "ä¸€éƒ¨å€¼å¾—æ·±å…¥é˜…è¯»çš„ä¼˜ç§€ä½œå“",
    "key_message": "å¼€å¯æ–‡å­¦ä¹‹æ—…"
  }},
  {{
    "slide_number": 2,
    "slide_type": "author",
    "title": "ä½œè€…ä»‹ç»",
    "subtitle": "äº†è§£åˆ›ä½œèƒŒæ™¯",
    "main_content": "æ·±å…¥äº†è§£ä½œè€…çš„åˆ›ä½œå†ç¨‹å’Œæ–‡å­¦æˆå°±",
    "key_message": "ä½œè€…çš„æ–‡å­¦ä¸–ç•Œ"
  }},
  {{
    "slide_number": 3,
    "slide_type": "concept",
    "title": "æ ¸å¿ƒä¸»é¢˜",
    "subtitle": "æ€æƒ³å†…æ¶µ",
    "main_content": "æ¢è®¨ä½œå“ä¸­è•´å«çš„æ·±åˆ»æ€æƒ³å’Œäººç”Ÿå“²ç†",
    "key_message": "æ€æƒ³çš„åŠ›é‡"
  }},
  {{
    "slide_number": 4,
    "slide_type": "quote",
    "title": "ç»å…¸è¯­å¥",
    "subtitle": "æ–‡å­¦ä¹‹ç¾",
    "main_content": "å“å‘³ä½œå“ä¸­çš„ç»å…¸è¯­å¥å’Œä¼˜ç¾è¡¨è¾¾",
    "key_message": "è¯­è¨€çš„é­…åŠ›"
  }},
  {{
    "slide_number": 5,
    "slide_type": "summary",
    "title": "ç°å®æ„ä¹‰",
    "subtitle": "å½“ä»£ä»·å€¼",
    "main_content": "ã€Š{book_title}ã€‹å¯¹å½“ä»£è¯»è€…çš„å¯å‘å’Œæ„ä¹‰",
    "key_message": "æ–‡å­¦çš„æ°¸æ’ä»·å€¼"
  }}
]
```'''
    }]

def get_fallback_narrations_data(book_title: str) -> list:
    """å½“APIé…é¢ç”¨å®Œæ—¶ï¼Œè¿”å›é»˜è®¤çš„è§£è¯´è¯æ•°æ®"""
    return [{
        "raw_content": f'''```json
[
  {{
    "slide_number": 1,
    "opening": "æ¬¢è¿å¤§å®¶ï¼Œä»Šå¤©æˆ‘ä»¬æ¥åˆ†äº«ä¸€éƒ¨ä¼˜ç§€çš„æ–‡å­¦ä½œå“ã€‚",
    "main_narration": "ã€Š{book_title}ã€‹æ˜¯ä¸€éƒ¨æ·±å—è¯»è€…å–œçˆ±çš„ç»å…¸ä½œå“ï¼Œå®ƒä»¥ç‹¬ç‰¹çš„è§†è§’å’Œæ·±åˆ»çš„æ€è€ƒï¼Œä¸ºæˆ‘ä»¬å±•ç°äº†ä¸°å¯Œçš„äººç”Ÿç”»å·ã€‚è¿™éƒ¨ä½œå“ä¸ä»…å…·æœ‰å¾ˆé«˜çš„æ–‡å­¦ä»·å€¼ï¼Œæ›´èƒ½ç»™æˆ‘ä»¬å¸¦æ¥æ·±åˆ»çš„äººç”Ÿå¯ç¤ºã€‚",
    "key_emphasis": "ä¸€éƒ¨å€¼å¾—åå¤é˜…è¯»çš„ç»å…¸ä¹‹ä½œ",
    "transition": "è®©æˆ‘ä»¬å…ˆæ¥äº†è§£ä¸€ä¸‹è¿™éƒ¨ä½œå“çš„ä½œè€…ã€‚"
  }},
  {{
    "slide_number": 2,
    "opening": "äº†è§£ä½œè€…ï¼Œæœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°ç†è§£ä½œå“ã€‚",
    "main_narration": "ä½œè€…ä»¥å…¶æ·±åšçš„æ–‡å­¦åŠŸåº•å’Œç‹¬ç‰¹çš„åˆ›ä½œé£æ ¼ï¼Œåˆ›ä½œäº†è¿™éƒ¨ä»¤äººå°è±¡æ·±åˆ»çš„ä½œå“ã€‚é€šè¿‡äº†è§£ä½œè€…çš„åˆ›ä½œèƒŒæ™¯å’Œäººç”Ÿç»å†ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ›´æ·±å…¥åœ°ç†è§£ä½œå“æ‰€è¦è¡¨è¾¾çš„æ€æƒ³å†…æ¶µã€‚",
    "key_emphasis": "ä½œè€…çš„äººç”Ÿé˜…å†ä¸°å¯Œäº†ä½œå“çš„å†…æ¶µ",
    "transition": "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬æ¢è®¨ä½œå“çš„æ ¸å¿ƒä¸»é¢˜ã€‚"
  }},
  {{
    "slide_number": 3,
    "opening": "æ¯éƒ¨ä¼˜ç§€çš„ä½œå“éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æ€æƒ³å†…æ¶µã€‚",
    "main_narration": "ã€Š{book_title}ã€‹é€šè¿‡ç”ŸåŠ¨çš„æ•…äº‹æƒ…èŠ‚å’Œæ·±åˆ»çš„äººç‰©åˆ»ç”»ï¼Œæ¢è®¨äº†äººç”Ÿçš„æ„ä¹‰ã€äººæ€§çš„å¤æ‚ä»¥åŠç¤¾ä¼šç°è±¡ç­‰é‡è¦ä¸»é¢˜ã€‚è¿™äº›ä¸»é¢˜ä¸ä»…å…·æœ‰æ™®éæ€§ï¼Œæ›´èƒ½å¼•å‘æˆ‘ä»¬å¯¹ç°å®ç”Ÿæ´»çš„æ·±å…¥æ€è€ƒã€‚",
    "key_emphasis": "æ€æƒ³çš„æ·±åº¦å†³å®šäº†ä½œå“çš„ä»·å€¼",
    "transition": "è®©æˆ‘ä»¬æ¥æ¬£èµä¸€äº›ä½œå“ä¸­çš„ç»å…¸è¯­å¥ã€‚"
  }},
  {{
    "slide_number": 4,
    "opening": "ä¼˜ç¾çš„è¯­è¨€æ˜¯æ–‡å­¦ä½œå“çš„é‡è¦ç‰¹è‰²ã€‚",
    "main_narration": "ã€Š{book_title}ã€‹åœ¨è¯­è¨€è¡¨è¾¾ä¸Šå…·æœ‰ç‹¬ç‰¹çš„é­…åŠ›ï¼Œä½œè€…è¿ç”¨ç²¾ç»ƒè€Œå¯Œæœ‰è¯—æ„çš„è¯­è¨€ï¼Œåˆ›é€ å‡ºè®¸å¤šä»¤äººéš¾å¿˜çš„ç»å…¸è¯­å¥ã€‚è¿™äº›è¯­å¥ä¸ä»…å±•ç°äº†ä½œè€…çš„æ–‡å­¦åŠŸåº•ï¼Œæ›´èƒ½è§¦åŠ¨è¯»è€…çš„å¿ƒçµã€‚",
    "key_emphasis": "è¯­è¨€çš„ç¾æ„Ÿæå‡äº†é˜…è¯»ä½“éªŒ",
    "transition": "æœ€åï¼Œè®©æˆ‘ä»¬æ€è€ƒè¿™éƒ¨ä½œå“çš„ç°å®æ„ä¹‰ã€‚"
  }},
  {{
    "slide_number": 5,
    "opening": "ä¼˜ç§€çš„æ–‡å­¦ä½œå“æ€»æ˜¯å…·æœ‰è·¨è¶Šæ—¶ä»£çš„ä»·å€¼ã€‚",
    "main_narration": "ã€Š{book_title}ã€‹è™½ç„¶åˆ›ä½œäºç‰¹å®šçš„å†å²æ—¶æœŸï¼Œä½†å…¶æ‰€æ¢è®¨çš„ä¸»é¢˜å’Œæ€æƒ³åœ¨ä»Šå¤©ä»ç„¶å…·æœ‰é‡è¦çš„ç°å®æ„ä¹‰ã€‚å®ƒèƒ½å¤Ÿå¯å‘æˆ‘ä»¬æ€è€ƒäººç”Ÿï¼ŒæŒ‡å¯¼æˆ‘ä»¬çš„ç”Ÿæ´»ï¼Œè¿™æ­£æ˜¯ç»å…¸æ–‡å­¦ä½œå“çš„æ°¸æ’ä»·å€¼æ‰€åœ¨ã€‚",
    "key_emphasis": "ç»å…¸ä½œå“çš„ä»·å€¼åœ¨äºå…¶æ°¸æ’çš„å¯å‘æ„ä¹‰",
    "transition": "æ„Ÿè°¢å¤§å®¶çš„è†å¬ï¼Œå¸Œæœ›è¿™æ¬¡åˆ†äº«èƒ½å¤Ÿæ¿€å‘å¤§å®¶å¯¹é˜…è¯»çš„å…´è¶£ã€‚"
  }}
]
```'''
    }]

# -----------------------------------------------------------------------
# å¢å¼ºçš„æµå¼ç”Ÿæˆå™¨
# -----------------------------------------------------------------------

async def enhanced_llm_event_stream(
    topic: str,
    history: Optional[List[dict]] = None,
    model: str = QWEN_MODEL,
    user_id: Optional[int] = None,
    methodology: str = "dongyu_literature",
    voice_style: str = "professional_style",
    video_style: str = "classic_ppt",
    book_info: dict = None,
) -> AsyncGenerator[str, None]:
    """
    å¢å¼ºçš„æµå¼ç”Ÿæˆå™¨ï¼šæ”¯æŒæ–¹æ³•è®ºå®šåˆ¶å’Œè¯­éŸ³ç”Ÿæˆ
    """
    import asyncio  # åœ¨å‡½æ•°å¼€å¤´å¯¼å…¥ï¼Œç¡®ä¿æ•´ä¸ªå‡½æ•°éƒ½èƒ½ä½¿ç”¨
    
    history = history or []
    book_info = book_info or {}
    
    # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯IDç”¨äºä¿å­˜æ–‡ä»¶
    import uuid
    session_id = str(uuid.uuid4())
    
    try:
        # å¼€å§‹æ€è€ƒä¸è§„åˆ’é˜¶æ®µ
        yield f"data: {json.dumps({'log': 'ğŸ­ å¢å¼ºç”Ÿæˆæ¨¡å¼å¯åŠ¨...'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.5)
        
        book_title = book_info.get("title", "æœªçŸ¥")
        yield f"data: {json.dumps({'log': f'ğŸ“š ä¹¦ç±ï¼šã€Š{book_title}ã€‹'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'ğŸ­ æ–¹æ³•è®ºï¼š{methodology}'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'ğŸ™ï¸ è¯­éŸ³é£æ ¼ï¼š{voice_style}'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'ğŸ¬ è§†é¢‘é£æ ¼ï¼š{video_style}'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.5)
        
        yield f"data: {json.dumps({'log': 'ğŸ¯ åˆ¶å®šä¸ªæ€§åŒ–ç”Ÿæˆç­–ç•¥...'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ­¥éª¤1: åŸºäºæ–¹æ³•è®ºåˆ†æä¹¦ç±'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ­¥éª¤2: æŒ‰é£æ ¼è®¾è®¡PPTç»“æ„'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ­¥éª¤3: ç”Ÿæˆä¸ªæ€§åŒ–è§£è¯´è¯'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ­¥éª¤4: ç”ŸæˆHTMLå’Œè¯­éŸ³'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ æ­¥éª¤5: åå¤„ç†ä¼˜åŒ–'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.5)
        
        # æ­¥éª¤1ï¼šåŸºäºæ–¹æ³•è®ºæå–ä¹¦æœ¬æ•°æ® 
        yield f"data: {json.dumps({'log': 'ğŸ” [æ­¥éª¤1/5] åŸºäºæ–¹æ³•è®ºåˆ†æä¹¦ç±æ•°æ®...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'  â”œâ”€ ä½¿ç”¨ {methodology} æ–¹æ³•è®ºåˆ†æ'}, ensure_ascii=False)}\n\n"
        
        # æ„å»ºæ–¹æ³•è®ºç‰¹å®šçš„æç¤ºè¯
        methodology_context = f"""
ä½ æ­£åœ¨ä½¿ç”¨ {methodology} æ–¹æ³•è®ºæ¥åˆ†æä¹¦ç±ã€Š{book_info.get('title', 'æœªçŸ¥')}ã€‹ã€‚

è¯·ç‰¹åˆ«æ³¨æ„ï¼š
- å¦‚æœæ˜¯è‘£å®‡è¾‰å¼æ–¹æ³•è®ºï¼šæ³¨é‡æƒ…æ„Ÿå…±é¸£ã€ä¸ªäººç»å†æ¤å…¥ã€å¤ä»Šä¸­å¤–å¼•ç”¨
- å¦‚æœæ˜¯ç½—æŒ¯å®‡å¼æ–¹æ³•è®ºï¼šå¼ºè°ƒè®¤çŸ¥å‡çº§ã€æ—¶ä»£ç„¦è™‘ã€æ–¹æ³•è®ºæ‹†è§£
- ç¡®ä¿åˆ†æç»“æœä½“ç°æ‰€é€‰æ–¹æ³•è®ºçš„ç‰¹è‰²å’Œé£æ ¼
        """
        
        enhanced_topic = f"{topic}\n\nã€æ–¹æ³•è®ºä¸Šä¸‹æ–‡ã€‘\n{methodology_context}"
        
        try:
            book_data = await step1_extract_book_data(enhanced_topic, methodology=methodology)
        except Exception as e:
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
                yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸  APIè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®'}, ensure_ascii=False)}\n\n"
                book_data = get_fallback_book_data(book_info.get('title', topic))
            else:
                yield f"data: {json.dumps({'log': f'  â”œâ”€ âš ï¸  æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®: {str(e)}'}, ensure_ascii=False)}\n\n"
                book_data = get_fallback_book_data(book_info.get('title', topic))
        
        # æ·»åŠ æ–¹æ³•è®ºä¿¡æ¯åˆ°ä¹¦ç±æ•°æ®
        if isinstance(book_data, dict):
            book_data['methodology'] = methodology
            book_data['voice_style'] = voice_style
            book_data['video_style'] = video_style
        
        book_title = book_info.get('title', topic)
        yield f"data: {json.dumps({'log': f'  â”œâ”€ ä¹¦ç±åˆ†æå®Œæˆ: ã€Š{book_title}ã€‹'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… æ–¹æ³•è®ºç‰¹è‰²å·²èå…¥åˆ†æ'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # æ­¥éª¤2ï¼šåŸºäºé£æ ¼åˆ›å»ºPPTç”»é¢
        yield f"data: {json.dumps({'log': 'ğŸ¨ [æ­¥éª¤2/5] åŸºäºé£æ ¼è®¾è®¡PPTç»“æ„...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'  â”œâ”€ åº”ç”¨ {video_style} è§†é¢‘é£æ ¼'}, ensure_ascii=False)}\n\n"
        
        try:
            slides_data = await step2_create_ppt_slides(book_data, methodology=methodology, video_style=video_style)
        except Exception as e:
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
                yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸  APIè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨å¹»ç¯ç‰‡'}, ensure_ascii=False)}\n\n"
                slides_data = get_fallback_slides_data(book_title)
            else:
                yield f"data: {json.dumps({'log': f'  â”œâ”€ âš ï¸  æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨å¹»ç¯ç‰‡: {str(e)}'}, ensure_ascii=False)}\n\n"
                slides_data = get_fallback_slides_data(book_title)
        
        yield f"data: {json.dumps({'log': '  â”œâ”€ PPTç»“æ„è®¾è®¡å®Œæˆ'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… é£æ ¼ç‰¹è‰²å·²ä½“ç°'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # æ­¥éª¤3ï¼šç”Ÿæˆä¸ªæ€§åŒ–è§£è¯´è¯
        yield f"data: {json.dumps({'log': 'ğŸ™ï¸ [æ­¥éª¤3/5] ç”Ÿæˆä¸ªæ€§åŒ–è§£è¯´è¯...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': f'  â”œâ”€ é‡‡ç”¨ {voice_style} è¯­éŸ³é£æ ¼'}, ensure_ascii=False)}\n\n"
        
        try:
            narrations_data = await step3_create_narration(slides_data, book_data, methodology=methodology)
        except Exception as e:
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e) or "ConnectError" in str(e) or "SSL" in str(e) or "EOF" in str(e):
                yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸  APIè¿æ¥é—®é¢˜ï¼Œä½¿ç”¨å¤‡ç”¨è§£è¯´è¯'}, ensure_ascii=False)}\n\n"
                narrations_data = get_fallback_narrations_data(book_title)
            else:
                yield f"data: {json.dumps({'log': f'  â”œâ”€ âš ï¸  æœªçŸ¥é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨è§£è¯´è¯: {str(e)}'}, ensure_ascii=False)}\n\n"
                narrations_data = get_fallback_narrations_data(book_title)
        
        yield f"data: {json.dumps({'log': '  â”œâ”€ ä¸ªæ€§åŒ–è§£è¯´è¯ç”Ÿæˆå®Œæˆ'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… æ–¹æ³•è®ºé£æ ¼å·²èå…¥'}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.3)
        
        # æ­¥éª¤4ï¼šç”ŸæˆHTMLå’Œè¯­éŸ³
        yield f"data: {json.dumps({'log': 'ğŸŒ [æ­¥éª¤4/5] ç”ŸæˆHTMLæ¼”ç¤ºæ–‡ä»¶...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ•´åˆæ‰€æœ‰ç»„ä»¶'}, ensure_ascii=False)}\n\n"
        
        # ç»„åˆæ‰€æœ‰æ•°æ®
        combined_data = {
            "topic": topic,
            "book_data": book_data,
            "slides": slides_data,
            "narrations": narrations_data,
            "methodology": methodology,
            "voice_style": voice_style,
            "video_style": video_style
        }
        
        try:
            html_content = await step4_generate_html(slides_data, narrations_data, book_data, methodology=methodology, enable_voice=True, book_title=book_title)
        except Exception as e:
            yield f"data: {json.dumps({'log': f'  â”œâ”€ HTMLç”Ÿæˆé‡åˆ°é—®é¢˜: {str(e)}'}, ensure_ascii=False)}\n\n"
            # ä½¿ç”¨ç®€åŒ–çš„HTMLç”Ÿæˆ
            html_content = f"<html><body><h1>ã€Š{book_title}ã€‹</h1><p>æ¼”ç¤ºæ–‡ä»¶ç”Ÿæˆä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚</p></body></html>"
        
        yield f"data: {json.dumps({'log': '  â”œâ”€ HTMLæ–‡ä»¶ç”Ÿæˆå®Œæˆ'}, ensure_ascii=False)}\n\n"
        
        # æ­¥éª¤5ï¼šåå¤„ç†ä¼˜åŒ–ï¼ˆè¯­éŸ³ç”Ÿæˆç­‰ï¼‰
        yield f"data: {json.dumps({'log': 'ğŸµ [æ­¥éª¤5/5] åå¤„ç†ä¼˜åŒ–...'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â”œâ”€ æ·»åŠ è¯­éŸ³æ”¯æŒ'}, ensure_ascii=False)}\n\n"
        
        # ä¿å­˜æ–‡ä»¶
        output_dir = Path(f"outputs/{session_id}")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜HTMLæ–‡ä»¶
        html_file = output_dir / "presentation.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        # è¯­éŸ³ç”Ÿæˆé›†æˆï¼ˆä¼˜åŒ–åé‡æ–°å¯ç”¨ï¼‰
        voice_generated = False
        
        try:
            if voice_style and voice_style != "no_voice":
                yield f"data: {json.dumps({'log': '  â”œâ”€ æ­£åœ¨ç”Ÿæˆè¯­éŸ³æ–‡ä»¶...'}, ensure_ascii=False)}\n\n"
                
                # å¯¼å…¥è¯­éŸ³ç”Ÿæˆå™¨
                sys.path.append(str(Path(__file__).parent / "create"))
                from ppt_voice_generator import PPTVoiceGenerator
                
                # åˆå§‹åŒ–è¯­éŸ³ç”Ÿæˆå™¨
                voice_generator = PPTVoiceGenerator(
                    html_file=str(html_file),
                    audio_prefix=f"{session_id}_slide"
                )
                
                # ç”Ÿæˆè¯­éŸ³æ–‡ä»¶ - è®¾ç½®è¶…æ—¶ä¿æŠ¤
                try:
                    # ä½¿ç”¨ asyncio.wait_for è®¾ç½®è¶…æ—¶
                    voice_results = await asyncio.wait_for(
                        asyncio.to_thread(voice_generator.generate_all_audio),
                        timeout=60.0  # 60ç§’è¶…æ—¶
                    )
                    
                    if voice_results:
                        yield f"data: {json.dumps({'log': f'  â”œâ”€ âœ… è¯­éŸ³æ–‡ä»¶ç”Ÿæˆå®Œæˆ ({len(voice_results)}ä¸ªéŸ³é¢‘)'}, ensure_ascii=False)}\n\n"
                        # åˆ›å»ºæ’­æ”¾åˆ—è¡¨
                        voice_generator.create_playlist(voice_results)
                        yield f"data: {json.dumps({'log': '  â”œâ”€ âœ… æ’­æ”¾åˆ—è¡¨åˆ›å»ºå®Œæˆ'}, ensure_ascii=False)}\n\n"
                        voice_generated = True
                    else:
                        yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸ è¯­éŸ³ç”Ÿæˆå®Œæˆä½†ç»“æœä¸ºç©º'}, ensure_ascii=False)}\n\n"
                
                except asyncio.TimeoutError:
                    yield f"data: {json.dumps({'log': '  â”œâ”€ âš ï¸ è¯­éŸ³ç”Ÿæˆè¶…æ—¶ï¼Œè·³è¿‡è¯­éŸ³åŠŸèƒ½'}, ensure_ascii=False)}\n\n"
                
            else:
                yield f"data: {json.dumps({'log': '  â”œâ”€ â„¹ï¸ è·³è¿‡è¯­éŸ³ç”Ÿæˆï¼ˆç”¨æˆ·é€‰æ‹©ï¼‰'}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'log': f'  â”œâ”€ âš ï¸ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {str(e)}'}, ensure_ascii=False)}\n\n"
        
        yield f"data: {json.dumps({'log': '  â”œâ”€ ä¼˜åŒ–æ’­æ”¾ä½“éªŒ'}, ensure_ascii=False)}\n\n"
        yield f"data: {json.dumps({'log': '  â””â”€ âœ… åå¤„ç†å®Œæˆ'}, ensure_ascii=False)}\n\n"
        
        # ä¿å­˜æ•°æ®æ–‡ä»¶
        data_file = output_dir / "data.json"
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(combined_data, f, ensure_ascii=False, indent=2)
        
        # è¿”å›æˆåŠŸç»“æœ
        yield f"data: {json.dumps({'log': 'ğŸ‰ å¢å¼ºç”Ÿæˆå®Œæˆï¼', 'session_id': session_id}, ensure_ascii=False)}\n\n"
        
        result = {
            "status": "complete",
            "session_id": session_id,
            "html_url": f"/outputs/{session_id}/presentation.html",
            "methodology": methodology,
            "voice_style": voice_style,
            "video_style": video_style
        }
        
        yield f"data: {json.dumps(result, ensure_ascii=False)}\n\n"
        
    except Exception as e:
        print(f"Enhanced generation error: {e}")
        error_result = {
            "status": "error",
            "message": f"å¢å¼ºç”Ÿæˆå¤±è´¥: {str(e)}"
        }
        yield f"data: {json.dumps(error_result, ensure_ascii=False)}\n\n"

# -----------------------------------------------------------------------
# 3. è·¯ç”± (CHANGED: Now a POST request)
# -----------------------------------------------------------------------
@app.post("/generate")
async def generate(
    chat_request: ChatRequest,
    request: Request,
):
    """
    Main endpoint: POST /generate
    Accepts a JSON body with "topic" and optional "history".
    Returns an SSE stream with 4-step processing.
    """
    # è·å–å½“å‰ç”¨æˆ·
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    accumulated_response = ""
    session_id = None

    async def event_generator():
        nonlocal accumulated_response, session_id
        try:
            async for chunk in llm_event_stream(chat_request.topic, chat_request.history, user_id=user.id):
                accumulated_response += chunk
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«session_id
                if '"session_id"' in chunk:
                    try:
                        data = json.loads(chunk.replace('data: ', ''))
                        if 'session_id' in data:
                            session_id = data['session_id']
                    except:
                        pass
                
                if await request.is_disconnected():
                    break
                yield chunk
        except Exception as e:
            yield f"data: {json.dumps({'error': str(e)})}\n\n"

    async def wrapped_stream():
        async for chunk in event_generator():
            yield chunk

    headers = {
        "Cache-Control": "no-store",
        "Content-Type": "text/event-stream; charset=utf-8",
        "X-Accel-Buffering": "no",
    }
    return StreamingResponse(wrapped_stream(), headers=headers)

@app.post("/api/enhanced-generate")
async def enhanced_generate(
    request_data: EnhancedGenerateRequest,
    request: Request,
):
    """
    å¢å¼ºç‰ˆç”Ÿæˆç«¯ç‚¹ï¼šä½¿ç”¨æŒ‡å®šçš„æ–¹æ³•è®ºå’Œé£æ ¼é…ç½®
    """
    # è·å–å½“å‰ç”¨æˆ·
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        # åˆå§‹åŒ–æ–¹æ³•è®ºé…ç½®
        try:
            config = MethodologyConfig()
        except:
            config = None
        
        # æ„å»ºä¹¦ç±ä¿¡æ¯
        book_info = {
            "title": request_data.title,
            "author": request_data.author or "æœªçŸ¥ä½œè€…",
            "category": request_data.category or "æ–‡å­¦ç±»",
            "description": request_data.description or "",
            "user_intent": request_data.user_intent or ""
        }
        
        # ç”Ÿæˆæ–¹æ³•è®ºç‰¹å®šçš„æç¤ºè¯
        if config:
            methodology_prompt = config.generate_methodology_prompt(
                request_data.methodology, 
                book_info
            )
        else:
            methodology_prompt = f"""
è¯·ä½¿ç”¨ {request_data.methodology} æ–¹æ³•è®ºæ¥ä»‹ç»ä¹¦ç±ã€Š{request_data.title}ã€‹ã€‚

**ä¹¦ç±ä¿¡æ¯ï¼š**
- ä¹¦åï¼š{request_data.title}
- ä½œè€…ï¼š{request_data.author or 'æœªçŸ¥ä½œè€…'}
- åˆ†ç±»ï¼š{request_data.category or 'æ–‡å­¦ç±»'}

è¯·æ ¹æ®æ‰€é€‰æ–¹æ³•è®ºçš„ç‰¹ç‚¹æ¥ç»„ç»‡å†…å®¹ç»“æ„å’Œè¡¨è¾¾æ–¹å¼ã€‚
            """
        
        # åˆ›å»ºå¢å¼ºçš„èŠå¤©è¯·æ±‚ - è¿™é‡Œæ˜¯å…³é”®ï¼Œæˆ‘ä»¬éœ€è¦æ˜ç¡®æŒ‡ç¤ºAIä½¿ç”¨æ–¹æ³•è®º
        enhanced_topic = f"""
è¯·ä¸ºä¹¦ç±ã€Š{request_data.title}ã€‹ç”Ÿæˆä¸€ä¸ªä¸“ä¸šçš„ä»‹ç»æ¼”ç¤ºã€‚

**ä¹¦ç±åŸºæœ¬ä¿¡æ¯ï¼š**
- ä¹¦åï¼š{request_data.title}
- ä½œè€…ï¼š{request_data.author or 'æœªçŸ¥ä½œè€…'}
- åˆ†ç±»ï¼š{request_data.category or 'æ–‡å­¦ç±»'}
- è¯­è¨€ï¼š{request_data.language}
{f"- ç®€ä»‹ï¼š{request_data.description}" if request_data.description else ""}
{f"- ç‰¹åˆ«è¦æ±‚ï¼š{request_data.user_intent}" if request_data.user_intent else ""}

**æŒ‡å®šæ–¹æ³•è®ºï¼š**
{methodology_prompt}

**é£æ ¼é…ç½®ï¼š**
- è¯­éŸ³é£æ ¼ï¼š{request_data.voice_style}
- è§†é¢‘é£æ ¼ï¼š{request_data.video_style}

è¯·ä¸¥æ ¼æŒ‰ç…§é€‰å®šçš„æ–¹æ³•è®ºæ¥ç»„ç»‡å†…å®¹ç»“æ„å’Œè¡¨è¾¾æ–¹å¼ï¼Œç¡®ä¿ç”Ÿæˆçš„ä»‹ç»å…·æœ‰è¯¥æ–¹æ³•è®ºçš„ç‰¹è‰²å’Œé£æ ¼ã€‚

**é‡è¦è¦æ±‚ï¼š**
1. åœ¨ç”Ÿæˆslideså†…å®¹æ—¶ï¼Œå¿…é¡»ä½“ç°æ‰€é€‰æ–¹æ³•è®ºçš„æ ¸å¿ƒç‰¹ç‚¹
2. åœ¨ç”Ÿæˆnarrationsæ—¶ï¼Œå¿…é¡»é‡‡ç”¨å¯¹åº”çš„è¡¨è¾¾é£æ ¼å’Œè¯­è°ƒ
3. ç¡®ä¿ç”Ÿæˆçš„HTMLåŒ…å«data-speechå±æ€§ä»¥æ”¯æŒè¯­éŸ³ç”Ÿæˆ
4. æ•´ä½“å†…å®¹åº”è¯¥å…·æœ‰æ˜æ˜¾çš„æ–¹æ³•è®ºç‰¹è‰²ï¼Œè€Œä¸æ˜¯é€šç”¨çš„ä»‹ç»æ–¹å¼
        """
        
        # ä½¿ç”¨å¢å¼ºçš„æµå¼ç”Ÿæˆå™¨
        async def enhanced_event_generator():
            session_id = None
            try:
                async for chunk in enhanced_llm_event_stream(
                    enhanced_topic, 
                    None,  # history
                    user_id=user.id,
                    methodology=request_data.methodology,
                    voice_style=request_data.voice_style,
                    video_style=request_data.video_style,
                    book_info=book_info
                ):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«session_id
                    if '"session_id"' in chunk:
                        try:
                            import json
                            lines = chunk.strip().split('\n')
                            for line in lines:
                                if line.startswith('data: ') and '"session_id"' in line:
                                    data = json.loads(line[6:])
                                    if 'session_id' in data:
                                        session_id = data['session_id']
                                        # ä¿å­˜å¢å¼ºé…ç½®åˆ°session
                                        await save_enhanced_config(session_id, request_data)
                                        break
                        except Exception as e:
                            print(f"è§£æsession_idå¤±è´¥: {e}")
                    
                    yield chunk
                    await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ

            except Exception as e:
                print(f"Enhanced generation error: {e}")
                error_data = {
                    "status": "error",
                    "message": f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            enhanced_event_generator(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/event-stream",
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¢å¼ºç”Ÿæˆå¤±è´¥: {str(e)}")

async def save_enhanced_config(session_id: str, config: EnhancedGenerateRequest):
    """ä¿å­˜å¢å¼ºé…ç½®åˆ°sessionç›®å½•"""
    try:
        session_dir = Path(f"outputs/{session_id}")
        if session_dir.exists():
            config_path = session_dir / "enhanced_config.json"
            config_data = {
                "methodology": config.methodology,
                "voice_style": config.voice_style,
                "video_style": config.video_style,
                "book_info": {
                    "title": config.title,
                    "author": config.author,
                    "category": config.category,
                    "language": config.language,
                    "description": config.description,
                    "user_intent": config.user_intent
                },
                "timestamp": datetime.now().isoformat()
            }
            
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
                
    except Exception as e:
        print(f"ä¿å­˜å¢å¼ºé…ç½®å¤±è´¥: {e}")

@app.post("/step/{step_number}")
async def execute_step(step_number: int, chat_request: ChatRequest):
    """
    Execute individual steps:
    1 - Extract book data
    2 - Create PPT slides  
    3 - Create narration
    4 - Generate HTML
    """
    try:
        if step_number == 1:
            result = await step1_extract_book_data(chat_request.topic)
            return {"step": 1, "result": result}
        elif step_number == 2:
            # For step 2, we need book_data from previous step or history
            book_data = chat_request.history[-1] if chat_request.history else {}
            result = await step2_create_ppt_slides(book_data)
            return {"step": 2, "result": result}
        elif step_number == 3:
            # For step 3, we need both book_data and slides
            if len(chat_request.history) >= 2:
                book_data = chat_request.history[-2]
                slides = chat_request.history[-1]
                result = await step3_create_narration(slides, book_data)
                return {"step": 3, "result": result}
            else:
                return {"error": "éœ€è¦å‰é¢æ­¥éª¤çš„æ•°æ®"}
        elif step_number == 4:
            # For step 4, we need book_data, slides, and narrations
            if len(chat_request.history) >= 3:
                book_data = chat_request.history[-3]
                slides = chat_request.history[-2] 
                narrations = chat_request.history[-1]
                result = await step4_generate_html(slides, narrations, book_data)
                return {"step": 4, "result": result}
            else:
                return {"error": "éœ€è¦å‰é¢æ­¥éª¤çš„æ•°æ®"}
        else:
            return {"error": "æ— æ•ˆçš„æ­¥éª¤å·ï¼Œè¯·ä½¿ç”¨1-4"}
    except Exception as e:
        return {"error": str(e)}

@app.get("/outputs/{session_id}")
async def get_generated_content(session_id: str):
    """
    è·å–å·²ç”Ÿæˆçš„å†…å®¹ä¿¡æ¯
    """
    import os
    output_dir = f"outputs/{session_id}"
    
    if not os.path.exists(output_dir):
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨æˆ–å†…å®¹æœªæ‰¾åˆ°")
    
    files = []
    for filename in os.listdir(output_dir):
        file_path = os.path.join(output_dir, filename)
        if os.path.isfile(file_path):
            files.append({
                "name": filename,
                "size": os.path.getsize(file_path),
                "modified": datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat()
            })
    
    return {
        "session_id": session_id,
        "output_path": output_dir,
        "files": files,
        "html_url": f"/outputs/{session_id}/presentation.html"
    }

@app.get("/outputs/{session_id}/{filename}")
async def serve_generated_file(session_id: str, filename: str):
    """
    æä¾›ç”Ÿæˆçš„æ–‡ä»¶è®¿é—®ï¼ŒHTMLæ–‡ä»¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼Œå…¶ä»–æ–‡ä»¶ä¸‹è½½
    """
    import os
    from fastapi.responses import FileResponse
    
    file_path = os.path.join("outputs", session_id, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½®ä¸åŒçš„åª’ä½“ç±»å‹
    if filename.endswith('.html'):
        # HTMLæ–‡ä»¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼ˆä¸è®¾ç½®filenameå‚æ•°é¿å…ä¸‹è½½ï¼‰
        return FileResponse(
            path=file_path,
            media_type='text/html; charset=utf-8',
            headers={
                "Cache-Control": "no-cache",
                "Content-Disposition": "inline"  # å¼ºåˆ¶åœ¨æµè§ˆå™¨ä¸­æ˜¾ç¤º
            }
        )
    elif filename.endswith('.json'):
        # JSONæ–‡ä»¶åœ¨æµè§ˆå™¨ä¸­æ˜¾ç¤º
        return FileResponse(
            path=file_path,
            media_type='application/json; charset=utf-8',
            headers={"Content-Disposition": "inline"}
        )
    else:
        # å…¶ä»–æ–‡ä»¶ä½œä¸ºä¸‹è½½
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type='application/octet-stream'
        )

@app.post("/regenerate/{session_id}")
async def regenerate_ppt(session_id: str):
    """
    é‡æ–°ç”ŸæˆæŒ‡å®šä¼šè¯çš„PPTï¼ˆä½¿ç”¨æ–°çš„æ¨¡æ¿ï¼‰
    """
    import os
    
    # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
    data_file = os.path.join("outputs", session_id, "data.json")
    if not os.path.exists(data_file):
        raise HTTPException(status_code=404, detail="ä¼šè¯æ•°æ®ä¸å­˜åœ¨")
    
    # è¯»å–åŸå§‹æ•°æ®
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # é‡æ–°ç”ŸæˆHTML
    html_content = await step4_generate_html(
        data['slides'], 
        data['narrations'], 
        data['book_data']
    )
    
    # ä¿å­˜æ–°çš„HTMLæ–‡ä»¶
    html_file = os.path.join("outputs", session_id, "presentation.html")
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    return {
        "message": "PPTé‡æ–°ç”Ÿæˆå®Œæˆ",
        "session_id": session_id,
        "html_url": f"/outputs/{session_id}/presentation.html",
        "regenerated_at": datetime.now(shanghai_tz).isoformat()
    }



@app.get("/api/ppt-preview/{session_id}")
async def get_ppt_preview(session_id: str):
    """
    è·å–PPTé¢„è§ˆä¿¡æ¯
    """
    import os
    
    data_file = f"outputs/{session_id}/data.json"
    if not os.path.exists(data_file):
        raise HTTPException(status_code=404, detail="PPTä¸å­˜åœ¨")
    
    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # è§£ææ•°æ®
        book_data = data.get('book_data', {})
        slides_data = data.get('slides', [])
        
        parsed_book_data = parse_ai_response(book_data)
        parsed_slides = parse_ai_response(slides_data)
        
        book_title = extract_book_title(parsed_book_data)
        
        # è·å–å‰3é¡µå¹»ç¯ç‰‡ä½œä¸ºé¢„è§ˆ
        preview_slides = []
        if isinstance(parsed_slides, list):
            for i, slide in enumerate(parsed_slides[:3]):
                if isinstance(slide, dict):
                    preview_slides.append({
                        'title': slide.get('title', f'ç¬¬{i+1}é¡µ'),
                        'subtitle': slide.get('subtitle', ''),
                        'content': slide.get('main_content', slide.get('content', ''))[:100] + '...'
                    })
        
        return {
            'session_id': session_id,
            'title': book_title,
            'topic': data.get('topic', ''),
            'preview_slides': preview_slides,
            'total_slides': len(parsed_slides) if isinstance(parsed_slides, list) else 0
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–é¢„è§ˆå¤±è´¥: {str(e)}")

@app.get("/api/generated-ppts")
async def get_generated_ppts(
    limit: int = 10, 
    page: int = 1, 
    category_id: str = None,
    search: str = None
):
    """è·å–å·²ç”Ÿæˆçš„PPTåˆ—è¡¨"""
    import os
    import json
    from pathlib import Path
    
    try:
        outputs_dir = Path("outputs")
        if not outputs_dir.exists():
            return {"ppts": []}
        
        ppt_list = []
        
        # éå†outputsç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•
        for session_dir in outputs_dir.iterdir():
            if session_dir.is_dir():
                data_file = session_dir / "data.json"
                html_file = session_dir / "presentation.html"
                
                if data_file.exists() and html_file.exists():
                    try:
                        # è¯»å–æ•°æ®æ–‡ä»¶è·å–PPTä¿¡æ¯
                        with open(data_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # è·å–æ–‡ä»¶åˆ›å»ºæ—¶é—´
                        created_time = datetime.fromtimestamp(
                            data_file.stat().st_ctime, 
                            tz=shanghai_tz
                        ).strftime("%Y-%m-%d %H:%M")
                        
                        # è·å–å°é¢ä¿¡æ¯
                        book_data = data.get("book_data", {})
                        cover_url = book_data.get("cover_url", get_default_book_cover(data.get("topic", "æœªçŸ¥ä¸»é¢˜")))
                        
                        # è·å–ä¹¦å - ä¼˜å…ˆä»book_dataä¸­æå–
                        title = data.get("topic", "æœªçŸ¥ä¸»é¢˜")  # é»˜è®¤å€¼
                        if book_data:
                            # å°è¯•ä»book_dataä¸­æå–ä¹¦å
                            if 'title' in book_data:
                                title = book_data['title']
                            elif 'raw_content' in book_data:
                                # å°è¯•ä»raw_contentä¸­è§£æJSONè·å–ä¹¦å
                                try:
                                    raw_content = book_data['raw_content']
                                    if 'title' in raw_content:
                                        import json as json_parser
                                        # å°è¯•è§£æJSON
                                        if raw_content.strip().startswith('```json'):
                                            json_start = raw_content.find('{')
                                            json_end = raw_content.rfind('}') + 1
                                            if json_start != -1 and json_end > json_start:
                                                parsed_data = json_parser.loads(raw_content[json_start:json_end])
                                                if 'book_info' in parsed_data and 'title' in parsed_data['book_info']:
                                                    title = parsed_data['book_info']['title']
                                except:
                                    pass
                            
                            # å¦‚æœè¿˜æ˜¯åŸå§‹çš„é•¿æ–‡æœ¬ï¼Œå°è¯•ä»topicä¸­æå–ä¹¦å
                            if len(title) > 100:
                                import re
                                # å°è¯•åŒ¹é…ã€Šä¹¦åã€‹æ ¼å¼
                                title_match = re.search(r'ã€Š([^ã€‹]+)ã€‹', title)
                                if title_match:
                                    title = title_match.group(1)
                                else:
                                    # å°è¯•åŒ¹é…"ä¹¦åï¼š"æ ¼å¼
                                    title_match = re.search(r'ä¹¦å[ï¼š:]\s*([^\n\-]+)', title)
                                    if title_match:
                                        title = title_match.group(1).strip()
                                        title = re.sub(r'\s*-\s*ä½œè€….*$', '', title)
                                        title = re.sub(r'\s*-\s*åˆ†ç±».*$', '', title)
                                        title = title.strip()
                        
                        # è½¬æ¢æœ¬åœ°å°é¢è·¯å¾„ä¸ºURL
                        if cover_url.startswith('covers/'):
                            cover_url = f"/covers/{cover_url.replace('covers/', '')}"
                        
                        # è·å–åˆ†ç±»ä¿¡æ¯
                        ppt_category_id = book_data.get("category_id", "literature")
                        category_name = book_data.get("category_name", "æ–‡å­¦ç±»")
                        category_color = book_data.get("category_color", "#E74C3C")
                        category_icon = book_data.get("category_icon", "ğŸ“–")
                        
                        ppt_info = {
                            "session_id": session_dir.name,
                            "title": title,
                            "created_time": created_time,
                            "html_url": f"/outputs/{session_dir.name}/presentation.html",
                            "preview_url": f"/ppt-preview/{session_dir.name}",
                            "cover_url": cover_url,
                            "category_id": ppt_category_id,
                            "category_name": category_name,
                            "category_color": category_color,
                            "category_icon": category_icon
                        }
                        
                        ppt_list.append(ppt_info)
                        
                    except (json.JSONDecodeError, KeyError) as e:
                        print(f"è¯»å–PPTæ•°æ®å¤±è´¥: {session_dir.name}, é”™è¯¯: {e}")
                        continue
        
        # ç­›é€‰åŠŸèƒ½
        if category_id:
            ppt_list = [ppt for ppt in ppt_list if ppt.get("category_id") == category_id]
        
        if search:
            search_lower = search.lower()
            ppt_list = [ppt for ppt in ppt_list if 
                       search_lower in ppt.get("title", "").lower() or 
                       search_lower in ppt.get("topic", "").lower()]
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        ppt_list.sort(key=lambda x: x["created_time"], reverse=True)
        
        # åˆ†é¡µåŠŸèƒ½
        total_count = len(ppt_list)
        total_pages = (total_count + limit - 1) // limit
        start_index = (page - 1) * limit
        end_index = start_index + limit
        paged_ppt_list = ppt_list[start_index:end_index]
        
        return {
            "ppts": paged_ppt_list,
            "pagination": {
                "current_page": page,
                "total_pages": total_pages,
                "total_count": total_count,
                "per_page": limit
            }
        }
        
    except Exception as e:
        print(f"è·å–PPTåˆ—è¡¨å¤±è´¥: {e}")
        return {"error": str(e), "ppts": []}

@app.get("/ppt-preview/{session_id}", response_class=HTMLResponse)
async def get_ppt_preview(session_id: str):
    """è·å–PPTé¢„è§ˆé¡µé¢"""
    import os
    from pathlib import Path
    
    try:
        html_file = Path(f"outputs/{session_id}/presentation.html")
        if html_file.exists():
            with open(html_file, 'r', encoding='utf-8') as f:
                return HTMLResponse(content=f.read())
        else:
            raise HTTPException(status_code=404, detail="PPTæ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¯»å–PPTæ–‡ä»¶å¤±è´¥: {str(e)}")

@app.get("/test_stream.html", response_class=HTMLResponse)
async def test_stream():
    """æµ‹è¯•æµæ•°æ®çš„é¡µé¢"""
    with open("test_stream.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

@app.get("/library", response_class=HTMLResponse)
async def library_page(request: Request):
    """å›¾ä¹¦é¦†é¡µé¢"""
    return templates.TemplateResponse(
        "library.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S")
        }
    )

@app.get("/enhanced-generator", response_class=HTMLResponse)
async def enhanced_generator_page(request: Request):
    """å¢å¼ºç‰ˆç”Ÿæˆå™¨é¡µé¢"""
    return templates.TemplateResponse(
        "enhanced_generator.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S")
        }
    )

@app.get("/", response_class=HTMLResponse)
async def read_index(request: Request):
    return templates.TemplateResponse(
        "index.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S")})

@app.get("/debug", response_class=HTMLResponse)
async def debug_page():
    with open("test_frontend_debug.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

@app.get("/simple_switch_test.html", response_class=HTMLResponse)
async def simple_switch_test(request: Request):
    return templates.TemplateResponse(
        "simple_switch_test.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S")})

@app.get("/test-static-cover", response_class=HTMLResponse)
async def test_static_cover():
    """æµ‹è¯•é™æ€å°é¢å›¾ç‰‡çš„é¡µé¢"""
    with open("test_static_cover.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

@app.get("/test-cover/{filename}")
async def test_cover_direct(filename: str):
    """ç›´æ¥æµ‹è¯•å°é¢æ–‡ä»¶è®¿é—®"""
    import os
    import urllib.parse
    from fastapi.responses import FileResponse
    
    # URLè§£ç æ–‡ä»¶å
    decoded_filename = urllib.parse.unquote(filename)
    cover_path = os.path.join("covers", decoded_filename)
    
    print(f"æµ‹è¯•è·¯ç”± - è¯·æ±‚çš„æ–‡ä»¶: {filename}")
    print(f"æµ‹è¯•è·¯ç”± - è§£ç åçš„æ–‡ä»¶å: {decoded_filename}")
    print(f"æµ‹è¯•è·¯ç”± - å®Œæ•´è·¯å¾„: {cover_path}")
    print(f"æµ‹è¯•è·¯ç”± - æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(cover_path)}")
    
    if os.path.exists(cover_path):
        return FileResponse(cover_path, media_type="image/jpeg")
    else:
        from fastapi.responses import JSONResponse
        return JSONResponse(status_code=404, content={"error": f"Cover image not found: {decoded_filename}"})

@app.get("/covers/{filename}")
async def serve_cover_image(filename: str):
    """æœåŠ¡coversç›®å½•ä¸­çš„å›¾ç‰‡æ–‡ä»¶"""
    import os
    import urllib.parse
    from fastapi.responses import FileResponse
    
    # URLè§£ç æ–‡ä»¶å
    decoded_filename = urllib.parse.unquote(filename)
    cover_path = os.path.join("covers", decoded_filename)
    
    print(f"è¯·æ±‚çš„æ–‡ä»¶: {filename}")
    print(f"è§£ç åçš„æ–‡ä»¶å: {decoded_filename}")
    print(f"å®Œæ•´è·¯å¾„: {cover_path}")
    print(f"æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(cover_path)}")
    
    if os.path.exists(cover_path):
        return FileResponse(cover_path, media_type="image/jpeg")
    else:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›404
        from fastapi.responses import JSONResponse
        return JSONResponse(status_code=404, content={"error": f"Cover image not found: {decoded_filename}"})

@app.get("/ppt_audio/{filename}")
async def serve_audio_file(filename: str):
    """æä¾›éŸ³é¢‘æ–‡ä»¶æœåŠ¡"""
    try:
        from fastapi.responses import FileResponse
        import os
        
        audio_file_path = os.path.join("ppt_audio", filename)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_file_path):
            raise HTTPException(status_code=404, detail=f"éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°: {filename}")
        
        return FileResponse(
            path=audio_file_path,
            media_type="audio/mpeg",
            headers={"Cache-Control": "public, max-age=3600"}
        )
    except Exception as e:
        print(f"æä¾›éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="éŸ³é¢‘æ–‡ä»¶æœåŠ¡é”™è¯¯")

# -----------------------------------------------------------------------
# åˆ†ç±»ç®¡ç†APIç«¯ç‚¹
# -----------------------------------------------------------------------

@app.get("/api/categories")
async def get_categories():
    """
    è·å–æ‰€æœ‰åˆ†ç±»ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        categories = get_categories_summary()
        return {
            "success": True,
            "categories": categories
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

# æ–¹æ³•è®ºé…ç½®APIç«¯ç‚¹
# -----------------------------------------------------------------------

@app.get("/api/methodologies")
async def get_methodologies():
    """è·å–æ‰€æœ‰å¯ç”¨çš„ä»‹ç»æ–¹æ³•è®º"""
    try:
        config = MethodologyConfig()
        methodologies = config.get_all_methodologies()
        return {
            "success": True,
            "methodologies": methodologies
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "methodologies": []
        }

@app.get("/api/methodologies/suitable")
async def get_suitable_methodologies(category: str):
    """æ ¹æ®ä¹¦ç±åˆ†ç±»è·å–åˆé€‚çš„æ–¹æ³•è®º"""
    try:
        config = MethodologyConfig()
        suitable = config.get_suitable_methodologies(category)
        return {
            "success": True,
            "methodologies": suitable
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "methodologies": []
        }

@app.get("/api/voice-styles")
async def get_voice_styles():
    """è·å–å¯ç”¨çš„è¯­éŸ³é£æ ¼"""
    try:
        styles = VoiceConfig.get_voice_styles()
        return {
            "success": True,
            "styles": styles
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "styles": {}
        }

@app.get("/api/video-styles")
async def get_video_styles():
    """è·å–å¯ç”¨çš„è§†é¢‘é£æ ¼"""
    try:
        styles = VideoConfig.get_video_styles()
        return {
            "success": True,
            "styles": styles
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "styles": {}
        }

@app.get("/api/books")
async def get_books(category_id: str = None, search: str = None):
    """
    è·å–ä¹¦ç±åˆ—è¡¨ï¼Œæ”¯æŒæŒ‰åˆ†ç±»ç­›é€‰å’Œæœç´¢
    """
    try:
        if category_id:
            books = get_books_by_category_id(category_id)
        elif search:
            books = search_books_by_keyword(search)
        else:
            books = get_all_books_with_categories()
        
        return {
            "success": True,
            "books": books,
            "total": len(books)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/categories/{category_id}/books")
async def get_books_by_category(category_id: str):
    """
    è·å–æŒ‡å®šåˆ†ç±»çš„ä¹¦ç±
    """
    try:
        books = get_books_by_category_id(category_id)
        return {
            "success": True,
            "category_id": category_id,
            "books": books,
            "total": len(books)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/export-video")
async def export_video(request: VideoExportRequest):
    """å¯¼å‡ºPPTæ¼”ç¤ºè§†é¢‘"""
    try:
        # éªŒè¯session_idå’Œç›¸å…³æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        html_file_path = Path(f"outputs/{request.session_id}/{request.html_file}")
        if not html_file_path.exists():
            raise HTTPException(status_code=404, detail="æ¼”ç¤ºæ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        audio_dir = Path("ppt_audio")
        if not audio_dir.exists():
            raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨")
        
        # åŠ¨æ€å¯¼å…¥è§†é¢‘ç”Ÿæˆå™¨
        sys.path.append(str(Path("create").absolute()))
        from universal_ppt_video_generator import UniversalPPTVideoGenerator
        
        # åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œä¼ å…¥å®Œæ•´çš„HTMLæ–‡ä»¶è·¯å¾„
        full_html_path = str(html_file_path.absolute())
        
        # åˆ›å»ºè§†é¢‘ç”Ÿæˆå™¨å®ä¾‹
        generator = UniversalPPTVideoGenerator(
            html_file=full_html_path,
            audio_prefix=request.audio_prefix
        )
        
        # ä¿®æ”¹ç”Ÿæˆå™¨çš„éŸ³é¢‘ç›®å½•å’Œè¾“å‡ºç›®å½•
        generator.audio_dir = Path("ppt_audio")
        generator.output_dir = Path(f"outputs/{request.session_id}")
        
        # æ£€æŸ¥ä¾èµ–
        if not generator.check_dependencies():
            raise HTTPException(status_code=500, detail="ç³»ç»Ÿä¾èµ–ä¸æ»¡è¶³ï¼Œè¯·æ£€æŸ¥FFmpegå’ŒChromeæ˜¯å¦å®‰è£…")
        
        # ç”Ÿæˆè§†é¢‘
        result = generator.generate_video()
        
        if result and result.exists():
            # è·å–è§†é¢‘ä¿¡æ¯
            file_size = result.stat().st_size / (1024 * 1024)  # MB
            
            # è·å–è§†é¢‘æ—¶é•¿
            duration = 0
            try:
                duration_result = subprocess.run([
                    "ffprobe", "-v", "quiet", "-show_entries", "format=duration",
                    "-of", "csv=p=0", str(result)
                ], capture_output=True, text=True)
                if duration_result.returncode == 0:
                    duration = float(duration_result.stdout.strip())
            except:
                pass
            
            # è¿”å›æˆåŠŸå“åº”
            return {
                "success": True,
                "video_url": f"/outputs/{request.session_id}/{result.name}",
                "filename": result.name,
                "file_size": f"{file_size:.1f} MB",
                "duration": f"{duration:.1f}",
                "message": "è§†é¢‘ç”ŸæˆæˆåŠŸ"
            }
        else:
            return {
                "success": False,
                "error": "è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨"
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": f"è§†é¢‘ç”Ÿæˆé”™è¯¯ï¼š{str(e)}"
        }

# -----------------------------------------------------------------------
# è®¤è¯ç›¸å…³ä¾èµ–å’Œä¸­é—´ä»¶
# -----------------------------------------------------------------------

security = HTTPBearer()

async def get_current_user(request: Request):
    """è·å–å½“å‰ç”¨æˆ·"""
    # é¦–å…ˆå°è¯•ä»cookieè·å–session token
    session_token = request.cookies.get("session_token")
    if session_token:
        user = user_manager.get_user_by_session(session_token)
        if user:
            return user
    
    # å¦‚æœæ²¡æœ‰sessionï¼Œå°è¯•ä»Authorization headerè·å–JWT token
    try:
        credentials: HTTPAuthorizationCredentials = Depends(security)
        token = credentials.credentials
        username = verify_token(token)
        if username:
            user = user_manager.get_user_by_username(username)
            if user:
                return user
    except:
        pass
    
    return None

async def require_auth(request: Request):
    """è¦æ±‚è®¤è¯çš„ä¾èµ–"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="éœ€è¦ç™»å½•",
            headers={"WWW-Authenticate": "Bearer"},
        )
    return user

# -----------------------------------------------------------------------
# è®¤è¯ç›¸å…³è·¯ç”±
# -----------------------------------------------------------------------

@app.post("/api/register")
async def register(user_data: UserCreate):
    """ç”¨æˆ·æ³¨å†Œ"""
    # éªŒè¯è¾“å…¥
    if len(user_data.username) < 3:
        raise HTTPException(status_code=400, detail="ç”¨æˆ·åè‡³å°‘éœ€è¦3ä¸ªå­—ç¬¦")
    
    if len(user_data.password) < 6:
        raise HTTPException(status_code=400, detail="å¯†ç è‡³å°‘éœ€è¦6ä¸ªå­—ç¬¦")
    
    # åˆ›å»ºç”¨æˆ·
    user = user_manager.create_user(
        username=user_data.username,
        email=user_data.email,
        password=user_data.password
    )
    
    if not user:
        raise HTTPException(status_code=400, detail="ç”¨æˆ·åæˆ–é‚®ç®±å·²å­˜åœ¨")
    
    # åˆ›å»ºsession
    session_token = user_manager.create_session(user.id)
    
    response = {
        "success": True,
        "message": "æ³¨å†ŒæˆåŠŸ",
        "user": {
            "id": user.id,
            "username": user.username,
            "email": user.email,
            "created_at": user.created_at,
            "last_login": user.last_login
        }
    }
    
    # è®¾ç½®cookie
    from fastapi.responses import JSONResponse
    json_response = JSONResponse(content=response)
    json_response.set_cookie(
        key="session_token",
        value=session_token,
        httponly=True,
        max_age=86400,  # 24å°æ—¶
        samesite="lax"
    )
    
    return json_response

@app.post("/api/login")
async def login(user_data: UserLogin):
    """ç”¨æˆ·ç™»å½•"""
    user = user_manager.authenticate_user(user_data.username, user_data.password)
    
    if not user:
        raise HTTPException(status_code=401, detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
    
    # åˆ›å»ºsession
    session_token = user_manager.create_session(user.id)
    
    response = {
        "success": True,
        "message": "ç™»å½•æˆåŠŸ",
        "user": {
            "id": user.id,
            "username": user.username,
            "email": user.email,
            "created_at": user.created_at,
            "last_login": user.last_login
        }
    }
    
    # è®¾ç½®cookie
    from fastapi.responses import JSONResponse
    json_response = JSONResponse(content=response)
    json_response.set_cookie(
        key="session_token",
        value=session_token,
        httponly=True,
        max_age=86400,  # 24å°æ—¶
        samesite="lax"
    )
    
    return json_response

@app.post("/api/logout")
async def logout(request: Request):
    """ç”¨æˆ·ç™»å‡º"""
    session_token = request.cookies.get("session_token")
    if session_token:
        user_manager.delete_session(session_token)
    
    response = {"success": True, "message": "ç™»å‡ºæˆåŠŸ"}
    
    # æ¸…é™¤cookie
    from fastapi.responses import JSONResponse
    json_response = JSONResponse(content=response)
    json_response.delete_cookie(key="session_token")
    
    return json_response

@app.get("/api/user")
async def get_current_user_info(request: Request):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")
    
    return {
        "success": True,
        "user": {
            "id": user.id,
            "username": user.username,
            "email": user.email,
            "created_at": user.created_at,
            "last_login": user.last_login
        }
    }

@app.get("/login", response_class=HTMLResponse)
async def login_page(request: Request):
    """ç™»å½•é¡µé¢"""
    return templates.TemplateResponse("login.html", {"request": request})

@app.get("/register", response_class=HTMLResponse)
async def register_page(request: Request):
    """æ³¨å†Œé¡µé¢"""
    return templates.TemplateResponse("register.html", {"request": request})

@app.get("/bookshelf", response_class=HTMLResponse)
async def bookshelf_page(request: Request):
    """ä¸ªäººä¹¦æ¶é¡µé¢"""
    return templates.TemplateResponse(
        "bookshelf.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S")
        }
    )

@app.get("/recommendations", response_class=HTMLResponse)
async def recommendations_page(request: Request):
    """æ¨èé¡µé¢"""
    return templates.TemplateResponse(
        "recommendations.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S")
        }
    )

@app.get("/recommendation-agent", response_class=HTMLResponse)
async def recommendation_agent_page(request: Request):
    """å¼•å¯¼æ¨èä»£ç†é¡µé¢"""
    return templates.TemplateResponse(
        "recommendation_agent.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S")
        }
    )

@app.get("/api/user-ppts")
async def get_user_ppts(
    request: Request,
    limit: int = 20, 
    page: int = 1, 
    category_id: str = None,
    search: str = None
):
    """è·å–å½“å‰ç”¨æˆ·çš„PPTåˆ—è¡¨"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        from models import user_manager
        result = user_manager.get_user_ppts(
            user_id=user.id,
            limit=limit,
            page=page,
            category_id=category_id,
            search=search
        )
        return result
    except Exception as e:
        print(f"è·å–ç”¨æˆ·PPTåˆ—è¡¨å¤±è´¥: {e}")
        return {"error": str(e), "ppts": []}

@app.delete("/api/user-ppts/{session_id}")
async def delete_user_ppt(session_id: str, request: Request):
    """åˆ é™¤ç”¨æˆ·çš„PPT"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        from models import user_manager
        success = user_manager.delete_user_ppt(session_id, user.id)
        if success:
            return {"message": "PPTåˆ é™¤æˆåŠŸ"}
        else:
            raise HTTPException(status_code=404, detail="PPTä¸å­˜åœ¨æˆ–æ— æƒé™åˆ é™¤")
    except Exception as e:
        print(f"åˆ é™¤PPTå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="åˆ é™¤å¤±è´¥")

@app.get("/api/recommendations")
async def get_recommendations(request: Request, limit: int = 10):
    """è·å–ç”¨æˆ·æ¨èä¹¦ç±"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        from models import user_manager
        recommendations = user_manager.get_recommendations_for_user(user.id, limit)
        return {"recommendations": recommendations}
    except Exception as e:
        print(f"è·å–æ¨èå¤±è´¥: {e}")
        return {"recommendations": []}

@app.get("/api/books/search")
async def search_books_api(title: str = None, author: str = None, search: str = None):
    """ä¹¦ç±æœç´¢API"""
    try:
        # æ„å»ºæœç´¢å…³é”®è¯
        search_term = search or ""
        if title:
            search_term += f" {title}"
        if author:
            search_term += f" {author}"
        
        search_term = search_term.strip()
        
        if search_term:
            books = search_books_by_keyword(search_term)
        else:
            books = get_all_books_with_categories()
        
        return {
            "success": True,
            "books": books,
            "total": len(books)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "books": []
        }

@app.post("/api/recommendation/start")
async def start_recommendation_session(request: Request):
    """å¼€å§‹å¼•å¯¼æ¨èä¼šè¯"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        # è¿™é‡Œå¯ä»¥é›†æˆ guided_recommendation_agent.py çš„åŠŸèƒ½
        # ç›®å‰è¿”å›åŸºæœ¬å“åº”
        return {
            "success": True,
            "message": "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ç§äººé˜…è¯»é¡¾é—®ã€‚è®©æˆ‘å…ˆäº†è§£ä¸€ä¸‹ä½ çš„é˜…è¯»æƒ…å†µ...",
            "user_profile": {
                "reading_frequency": "æœªçŸ¥",
                "preferred_categories": [],
                "current_life_stage": "åˆ†æä¸­"
            },
            "user_info": {
                "username": user.username,
                "id": user.id
            }
        }
    except Exception as e:
        print(f"å¯åŠ¨æ¨èä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="å¯åŠ¨æ¨èä¼šè¯å¤±è´¥")

@app.get("/api/user")
async def get_current_user_info(request: Request):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    try:
        user = await get_current_user(request)
        if user:
            return {
                "success": True,
                "user": {
                    "id": user.id,
                    "username": user.username,
                    "email": getattr(user, 'email', '')
                }
            }
        else:
            return {"success": False, "user": None}
    except Exception as e:
        print(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/user-preferences")
async def get_user_preferences(request: Request):
    """è·å–ç”¨æˆ·åå¥½"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        from models import user_manager
        preferences = user_manager.get_user_preferences(user.id)
        return {"preferences": preferences}
    except Exception as e:
        print(f"è·å–ç”¨æˆ·åå¥½å¤±è´¥: {e}")
        return {"preferences": {}}

@app.get("/api/popular-books/{category_name}")
async def get_popular_books_by_category(
    category_name: str, 
    request: Request, 
    limit: int = 10
):
    """è·å–æŒ‡å®šåˆ†ç±»çš„çƒ­é—¨ä¹¦ç±"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        from models import user_manager
        books = user_manager.get_popular_books_by_category(
            category_name, 
            exclude_user_id=user.id, 
            limit=limit
        )
        return {"books": books}
    except Exception as e:
        print(f"è·å–çƒ­é—¨ä¹¦ç±å¤±è´¥: {e}")
        return {"books": []}

@app.post("/api/add-book-to-bookshelf")
async def add_book_to_bookshelf(request: Request):
    """æ·»åŠ ä¹¦ç±åˆ°ç”¨æˆ·ä¹¦æ¶"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        data = await request.json()
        title = data.get("title")
        author = data.get("author")
        cover_url = data.get("cover_url")
        category_id = data.get("category_id")
        category_name = data.get("category_name")
        category_color = data.get("category_color")
        category_icon = data.get("category_icon")
        source_type = data.get("source_type", "library")
        source_id = data.get("source_id")
        
        if not title:
            raise HTTPException(status_code=400, detail="ä¹¦ç±æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
        
        from models import user_manager
        
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å·²åœ¨ä¹¦æ¶ä¸­
        if user_manager.check_book_in_bookshelf(user.id, title, author):
            return {"success": False, "message": "è¯¥ä¹¦ç±å·²åœ¨æ‚¨çš„ä¹¦æ¶ä¸­"}
        
        # æ·»åŠ ä¹¦ç±åˆ°ä¹¦æ¶
        session_id = user_manager.add_book_to_bookshelf(
            user_id=user.id,
            title=title,
            author=author,
            cover_url=cover_url,
            category_id=category_id,
            category_name=category_name,
            category_color=category_color,
            category_icon=category_icon,
            source_type=source_type,
            source_id=source_id
        )
        
        if session_id:
            return {"success": True, "message": "ä¹¦ç±å·²æ·»åŠ åˆ°ä¹¦æ¶", "session_id": session_id}
        else:
            raise HTTPException(status_code=500, detail="æ·»åŠ ä¹¦ç±å¤±è´¥")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"æ·»åŠ ä¹¦ç±åˆ°ä¹¦æ¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ·»åŠ ä¹¦ç±å¤±è´¥")

@app.get("/api/check-book-in-bookshelf")
async def check_book_in_bookshelf(
    request: Request,
    title: str,
    author: str = None
):
    """æ£€æŸ¥ä¹¦ç±æ˜¯å¦å·²åœ¨ç”¨æˆ·ä¹¦æ¶ä¸­"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•")
    
    try:
        from models import user_manager
        is_in_bookshelf = user_manager.check_book_in_bookshelf(user.id, title, author)
        return {"in_bookshelf": is_in_bookshelf}
    except Exception as e:
        print(f"æ£€æŸ¥ä¹¦ç±æ˜¯å¦åœ¨ä¹¦æ¶ä¸­å¤±è´¥: {e}")
        return {"in_bookshelf": False}

# -----------------------------------------------------------------------
# è®¿è°ˆåŠŸèƒ½APIè·¯ç”±
# -----------------------------------------------------------------------
from interview_dialogue import get_dialogue_engine
from interview_content_processor import get_podcast_generator

class InterviewStartRequest(BaseModel):
    """è®¿è°ˆå¼€å§‹è¯·æ±‚"""
    book_title: str
    book_author: str
    user_intro: str

class InterviewMessageRequest(BaseModel):
    """è®¿è°ˆæ¶ˆæ¯è¯·æ±‚"""
    session_id: str
    message: str

class InterviewGenerateRequest(BaseModel):
    """è®¿è°ˆç”Ÿæˆè¯·æ±‚"""
    session_id: str

@app.post("/api/interview/start")
async def start_interview(request: InterviewStartRequest):
    """å¼€å§‹è®¿è°ˆ"""
    try:
        engine = get_dialogue_engine()
        result = engine.start_interview(
            request.book_title,
            request.book_author,
            request.user_intro
        )
        return result
    except Exception as e:
        print(f"å¼€å§‹è®¿è°ˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="å¼€å§‹è®¿è°ˆå¤±è´¥")

@app.post("/api/interview/message")
async def send_interview_message(request: InterviewMessageRequest):
    """å‘é€è®¿è°ˆæ¶ˆæ¯"""
    try:
        engine = get_dialogue_engine()
        result = await engine.process_user_message(
            request.session_id,
            request.message
        )
        return result
    except Exception as e:
        print(f"å¤„ç†è®¿è°ˆæ¶ˆæ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="å¤„ç†æ¶ˆæ¯å¤±è´¥")

@app.post("/api/interview/generate-podcast")
async def generate_interview_podcast(request: InterviewGenerateRequest):
    """ç”Ÿæˆè®¿è°ˆæ’­å®¢"""
    try:
        generator = get_podcast_generator()
        result = await generator.generate_podcast_content(request.session_id)
        return result
    except Exception as e:
        print(f"ç”Ÿæˆæ’­å®¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="ç”Ÿæˆæ’­å®¢å¤±è´¥")

@app.get("/api/interview/session/{session_id}")
async def get_interview_session(session_id: str):
    """è·å–è®¿è°ˆä¼šè¯ä¿¡æ¯"""
    try:
        from interview_user_model import get_session
        session = get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        engine = get_dialogue_engine()
        summary = engine.get_session_summary(session_id)
        return summary
    except HTTPException:
        raise
    except Exception as e:
        print(f"è·å–ä¼šè¯ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–ä¼šè¯ä¿¡æ¯å¤±è´¥")

@app.get("/api/book-info")
async def get_book_info(title: str, author: str = None):
    """è·å–ä¹¦ç±æ‰©å±•ä¿¡æ¯"""
    try:
        import sqlite3
        import os
        import json
        
        # æŸ¥è¯¢æ•°æ®åº“ä¸­çš„PPTä¿¡æ¯ (æ³¨æ„è¡¨åæ˜¯pptsï¼Œä¸æ˜¯presentations)
        query = """
        SELECT 
            session_id, title, author, category_name, cover_url, created_at
        FROM ppts 
        WHERE title LIKE ? 
        """
        params = [f"%{title}%"]
        
        if author:
            query += " AND author LIKE ?"
            params.append(f"%{author}%")
            
        query += " ORDER BY created_at DESC LIMIT 1"
        
        conn = sqlite3.connect("users.db")
        try:
            cursor = conn.execute(query, params)
            row = cursor.fetchone()
            
            if row:
                session_id = row[0]
                ppt_title = row[1]
                ppt_author = row[2]
                category_name = row[3]
                cover_url = row[4]
                created_at = row[5]
                
                # æ£€æŸ¥å¯¹åº”çš„PPTæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                ppt_path = f"outputs/{session_id}/presentation.html"
                data_path = f"outputs/{session_id}/data.json"
                
                ppt_exists = os.path.exists(ppt_path)
                description = f"å…³äºã€Š{ppt_title}ã€‹çš„æ·±åº¦è§£è¯»"
                
                # å¦‚æœdata.jsonå­˜åœ¨ï¼Œå°è¯•è¯»å–æ›´è¯¦ç»†çš„ä¿¡æ¯
                if os.path.exists(data_path):
                    try:
                        with open(data_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            book_data = data.get('book_data', {})
                            raw_content = book_data.get('raw_content', '')
                            if 'content_summary' in raw_content:
                                # æå–ç®€ä»‹ä¿¡æ¯
                                import re
                                summary_match = re.search(r'"content_summary":\s*\[(.*?)\]', raw_content, re.DOTALL)
                                if summary_match:
                                    description = "è¿™æ˜¯ä¸€éƒ¨ç»å…¸æ–‡å­¦ä½œå“..."
                    except:
                        pass
                
                return {
                    "id": session_id,
                    "title": ppt_title,
                    "author": ppt_author or "æœªçŸ¥ä½œè€…",
                    "category": category_name or "æœªåˆ†ç±»",
                    "description": description,
                    "created_at": created_at,
                    "cover_url": cover_url,
                    "ppt_exists": ppt_exists,
                    "ppt_url": f"/outputs/{session_id}/presentation.html" if ppt_exists else None,
                    "interview_count": 1,  # è‡³å°‘æœ‰ä¸€æ¬¡è®¿é—®è®°å½•
                    "podcast_count": 0,
                    "source": "library"
                }
            else:
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œè¿”å›é»˜è®¤ä¿¡æ¯
                return {
                    "title": title,
                    "author": author or "æœªçŸ¥ä½œè€…",
                    "category": "æ–‡å­¦ä½œå“",
                    "description": f"å…³äºã€Š{title}ã€‹çš„æ·±åº¦è®¿è°ˆ",
                    "created_at": datetime.now(shanghai_tz).isoformat(),
                    "ppt_exists": False,
                    "ppt_url": None,
                    "interview_count": 0,
                    "podcast_count": 0,
                    "source": "new"
                }
        finally:
            conn.close()
                
    except Exception as e:
        print(f"è·å–ä¹¦ç±ä¿¡æ¯å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
        return {
            "title": title,
            "author": author or "æœªçŸ¥ä½œè€…",
            "category": "æœªåˆ†ç±»",
            "description": f"å…³äºã€Š{title}ã€‹çš„æ·±åº¦è®¿è°ˆ",
            "created_at": datetime.now(shanghai_tz).isoformat(),
            "ppt_exists": False,
            "ppt_url": None,
            "interview_count": 0,
            "podcast_count": 0,
            "source": "error"
        }

@app.get("/interview", response_class=HTMLResponse)
async def interview_page(request: Request, book_title: str = None, book_author: str = None):
    """è¯»åæ„Ÿè®¿è°ˆé¡µé¢"""
    # å°è¯•ä»æ•°æ®åº“ä¸­æŸ¥æ‰¾å¯¹åº”çš„ä¹¦ç±ä¿¡æ¯
    book_info = None
    if book_title:
        try:
            import sqlite3
            conn = sqlite3.connect('fogsight.db')
            cursor = conn.cursor()
            
            # æŸ¥æ‰¾ä¹¦ç±ä¿¡æ¯
            cursor.execute("""
                SELECT session_id, title, author, cover_url, category_name, created_at 
                FROM presentations 
                WHERE title LIKE ? OR (author LIKE ? AND title LIKE ?)
                ORDER BY created_at DESC 
                LIMIT 1
            """, (f'%{book_title}%', f'%{book_author}%' if book_author else '%', f'%{book_title}%'))
            
            result = cursor.fetchone()
            if result:
                session_id, title, author, cover_url, category_name, created_at = result
                book_info = {
                    'session_id': session_id,
                    'title': title,
                    'author': author,
                    'cover_url': cover_url,
                    'category': category_name,
                    'created_at': created_at,
                    'found_in_library': True
                }
            conn.close()
        except Exception as e:
            print(f"æŸ¥è¯¢ä¹¦ç±ä¿¡æ¯å¤±è´¥: {e}")
    
    return templates.TemplateResponse(
        "interview.html", {
            "request": request,
            "time": datetime.now(shanghai_tz).strftime("%Y%m%d%H%M%S"),
            "book_title": book_title,
            "book_author": book_author,
            "book_info": book_info,
            "book_cover": book_info['cover_url'] if book_info else None,
            "book_description": f"å…³äºã€Š{book_title}ã€‹çš„æ·±åº¦è®¿è°ˆ" if book_title else "å¼€å§‹ä½ çš„è¯»åæ„Ÿè®¿è°ˆ"
        }
    )

# -----------------------------------------------------------------------
# 4. æœ¬åœ°å¯åŠ¨å‘½ä»¤
# -----------------------------------------------------------------------
# uvicorn appbook:app --reload --host 0.0.0.0 --port 8000


if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001, reload=False)
